# Comparing `tmp/openai_forward-0.1.7.tar.gz` & `tmp/openai_forward-0.1.8.tar.gz`

## Comparing `openai_forward-0.1.7.tar` & `openai_forward-0.1.8.tar`

### file list

```diff
@@ -1,17 +1,17 @@
--rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/__init__.py
--rw-r--r--   0        0        0     1499 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/__main__.py
--rw-r--r--   0        0        0     4576 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/_base.py
--rw-r--r--   0        0        0      677 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/app.py
--rw-r--r--   0        0        0     3109 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/config.py
--rw-r--r--   0        0        0      699 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/openai.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/content/__init__.py
--rw-r--r--   0        0        0     3418 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/content/chat.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/content/image.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/routers/__init__.py
--rw-r--r--   0        0        0      508 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/routers/openai_v1.py
--rw-r--r--   0        0        0     2272 2020-02-02 00:00:00.000000 openai_forward-0.1.7/openai_forward/routers/schemas.py
--rw-r--r--   0        0        0     1897 2020-02-02 00:00:00.000000 openai_forward-0.1.7/.gitignore
--rw-r--r--   0        0        0     1064 2020-02-02 00:00:00.000000 openai_forward-0.1.7/LICENSE
--rw-r--r--   0        0        0     7067 2020-02-02 00:00:00.000000 openai_forward-0.1.7/README.md
--rw-r--r--   0        0        0     1646 2020-02-02 00:00:00.000000 openai_forward-0.1.7/pyproject.toml
--rw-r--r--   0        0        0     8357 2020-02-02 00:00:00.000000 openai_forward-0.1.7/PKG-INFO
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/__init__.py
+-rw-r--r--   0        0        0     1505 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/__main__.py
+-rw-r--r--   0        0        0      675 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/app.py
+-rw-r--r--   0        0        0     5204 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/base.py
+-rw-r--r--   0        0        0     3135 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/config.py
+-rw-r--r--   0        0        0      694 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/openai.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/content/__init__.py
+-rw-r--r--   0        0        0     3418 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/content/chat.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/content/image.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/routers/__init__.py
+-rw-r--r--   0        0        0      510 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/routers/openai_v1.py
+-rw-r--r--   0        0        0     2272 2020-02-02 00:00:00.000000 openai_forward-0.1.8/openai_forward/routers/schemas.py
+-rw-r--r--   0        0        0     1897 2020-02-02 00:00:00.000000 openai_forward-0.1.8/.gitignore
+-rw-r--r--   0        0        0     1064 2020-02-02 00:00:00.000000 openai_forward-0.1.8/LICENSE
+-rw-r--r--   0        0        0     8655 2020-02-02 00:00:00.000000 openai_forward-0.1.8/README.md
+-rw-r--r--   0        0        0     1646 2020-02-02 00:00:00.000000 openai_forward-0.1.8/pyproject.toml
+-rw-r--r--   0        0        0     9945 2020-02-02 00:00:00.000000 openai_forward-0.1.8/PKG-INFO
```

### Comparing `openai_forward-0.1.7/openai_forward/__main__.py` & `openai_forward-0.1.8/openai_forward/__main__.py`

 * *Files 12% similar despite different names*

```diff
@@ -4,36 +4,38 @@
 
 
 class Cli:
     @staticmethod
     def run(port=8000,
             workers=1,
             api_key=None,
-            base_url='https://api.openai.com',
-            log_chat='true',
+            base_url=None,
+            log_chat=None,
             route_prefix=None,
             ip_whitelist=None,
             ip_blacklist=None,
             ):
         """ Run forwarding serve.
 
         Parameters
         ----------
 
         port: int, default 8000
         workers: int, default 1
         api_key: str, default None
-        base_url: str, default 'https://api.openai.com'
-        log_chat: str, default 'true'
+        base_url: str, default None
+        log_chat: str, default None
         route_prefix: str, default None
         ip_whitelist: str, default None
         ip_blacklist: str, default None
         """
-        os.environ['OPENAI_BASE_URL'] = base_url
-        os.environ['LOG_CHAT'] = log_chat
+        if base_url:
+            os.environ['OPENAI_BASE_URL'] = base_url
+        if log_chat:
+            os.environ['LOG_CHAT'] = log_chat
         if api_key:
             os.environ['OPENAI_API_KEY'] = api_key
         if route_prefix:
             os.environ['ROUTE_PREFIX'] = route_prefix
         if ip_whitelist:
             os.environ['IP_WHITELIST'] = ip_whitelist
         if ip_blacklist:
```

### Comparing `openai_forward-0.1.7/openai_forward/_base.py` & `openai_forward-0.1.8/openai_forward/base.py`

 * *Files 13% similar despite different names*

```diff
@@ -6,27 +6,29 @@
 import os
 from itertools import cycle
 from .content.chat import parse_chat_completions, ChatSaver
 from .config import env2list
 
 
 class OpenaiBase:
-    _base_url = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com").strip()
-    _LOG_CHAT = os.environ.get("LOG_CHAT", "False").lower() == "true"
-    _ROUTE_PREFIX = os.environ.get("ROUTE_PREFIX", "").strip()
-    _default_api_key_list = env2list("OPENAI_API_KEY", sep=" ")
-    _cycle_api_key = cycle(_default_api_key_list)
+    BASE_URL = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com").strip()
+    ROUTE_PREFIX = os.environ.get("ROUTE_PREFIX", "").strip()
+    _LOG_CHAT = os.environ.get("LOG_CHAT", "False").strip().lower() == "true"
+    _openai_api_key_list = env2list("OPENAI_API_KEY", sep=" ")
+    _cycle_api_key = cycle(_openai_api_key_list)
+    _FWD_KEYS = env2list("FORWARD_KEY", sep=" ")
+    _use_forward_key = _openai_api_key_list != [] and _FWD_KEYS != []
     IP_WHITELIST = env2list("IP_WHITELIST", sep=" ")
     IP_BLACKLIST = env2list("IP_BLACKLIST", sep=" ")
 
-    if _ROUTE_PREFIX:
-        if _ROUTE_PREFIX.endswith('/'):
-            _ROUTE_PREFIX = _ROUTE_PREFIX[:-1]
-        if not _ROUTE_PREFIX.startswith('/'):
-            _ROUTE_PREFIX = '/' + _ROUTE_PREFIX
+    if ROUTE_PREFIX:
+        if ROUTE_PREFIX.endswith('/'):
+            ROUTE_PREFIX = ROUTE_PREFIX[:-1]
+        if not ROUTE_PREFIX.startswith('/'):
+            ROUTE_PREFIX = '/' + ROUTE_PREFIX
     timeout = 30
     chatsaver = ChatSaver(save_interval=10)
 
     def validate_request_host(self, ip):
         if self.IP_WHITELIST and ip not in self.IP_WHITELIST:
             raise HTTPException(status_code=status.HTTP_403_FORBIDDEN,
                                 detail=f"Forbidden, ip={ip} not in whitelist!")
@@ -50,55 +52,65 @@
         except Exception as e:
             logger.debug(f"log chat (not) error:\n{e=}")
 
     @classmethod
     async def _reverse_proxy(cls, request: Request):
         client: httpx.AsyncClient = request.app.state.client
         url_path = request.url.path
-        url_path = url_path[len(cls._ROUTE_PREFIX):]
+        url_path = url_path[len(cls.ROUTE_PREFIX):]
         url = httpx.URL(path=url_path, query=request.url.query.encode('utf-8'))
         headers = dict(request.headers)
         auth = headers.pop("authorization", None)
         if auth and str(auth).startswith("Bearer sk-"):
             tmp_headers = {'Authorization': auth}
-        elif cls._default_api_key_list:
-            auth = "Bearer " + next(cls._cycle_api_key)
-            tmp_headers = {'Authorization': auth}
+        elif cls._openai_api_key_list:
+            logger.info(f"Use forward key: {cls._use_forward_key}")
+            if cls._use_forward_key:
+                fk_prefix = "Bearer fk-"
+                logger.info(f"current forward key: {auth}")
+                if auth and str(auth).startswith(fk_prefix) and auth[len("Bearer "):] in cls._FWD_KEYS:
+                    auth = "Bearer " + next(cls._cycle_api_key)
+                    tmp_headers = {'Authorization': auth}
+                else:
+                    tmp_headers = {}
+            else:
+                auth = "Bearer " + next(cls._cycle_api_key)
+                tmp_headers = {'Authorization': auth}
         else:
             tmp_headers = {}
 
-        headers.pop("host", None)
-        headers.update(tmp_headers)
         if cls._LOG_CHAT:
             try:
                 input_info = await request.json()
                 msgs = input_info['messages']
                 cls.chatsaver.add_chat({
                     "host": request.client.host,
                     "model": input_info['model'],
                     "messages": [{msg['role']: msg['content']} for msg in msgs],
                 })
             except Exception as e:
                 logger.debug(f"log chat (not) error:\n{request.client.host=}: {e}")
+
+        headers.pop("host", None)
+        headers.update(tmp_headers)
+
         req = client.build_request(
             request.method, url, headers=headers,
             content=request.stream(),
             timeout=cls.timeout,
         )
-        logger.warning(f"{url=}")
-
         try:
             r = await client.send(req, stream=True)
-        except httpx.ConnectError as e:
+        except (httpx.ConnectError, httpx.ConnectTimeout) as e:
             error_info = f"{type(e)}: {e} | " \
-                         f"Please check if host={request.client.host} can access [{cls._base_url}] successfully."
+                         f"Please check if host={request.client.host} can access [{cls.BASE_URL}] successfully."
             logger.error(error_info)
             raise HTTPException(status_code=status.HTTP_504_GATEWAY_TIMEOUT, detail=error_info)
         except Exception as e:
-            error_info = f"{type(e)}: {str(e)}"
+            error_info = f"{type(e)}: {e}"
             logger.error(error_info)
             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=error_info)
 
         aiter_bytes = cls.aiter_bytes(r) if cls._LOG_CHAT else r.aiter_bytes()
         return StreamingResponse(
             aiter_bytes,
             status_code=r.status_code,
```

### Comparing `openai_forward-0.1.7/openai_forward/app.py` & `openai_forward-0.1.8/openai_forward/app.py`

 * *Files 18% similar despite different names*

```diff
@@ -6,18 +6,18 @@
 app = create_app(title="openai_forward", version="1.0")
 openai = Openai()
 use_http2 = False
 
 
 @app.on_event('startup')
 async def startup_event():
-    app.state.client = httpx.AsyncClient(base_url=Openai._base_url, http2=use_http2)
+    app.state.client = httpx.AsyncClient(base_url=Openai.BASE_URL, http2=use_http2)
 
 
 @app.on_event('shutdown')
 async def shutdown_event():
     await app.state.client.aclose()
 
 
-app.add_route(openai._ROUTE_PREFIX + '/{api_path:path}', openai.reverse_proxy,
+app.add_route(openai.ROUTE_PREFIX + '/{api_path:path}', openai.reverse_proxy,
               methods=['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS', 'HEAD', 'PATCH', 'TRACE'])
 app.include_router(router_v1)
```

### Comparing `openai_forward-0.1.7/openai_forward/config.py` & `openai_forward-0.1.8/openai_forward/config.py`

 * *Files 5% similar despite different names*

```diff
@@ -2,27 +2,26 @@
 import orjson
 from sparrow import relp
 from typing import Union, List, Dict
 import sys
 import logging
 import os
 import time
-import pytz
 
 
 class InterceptHandler(logging.Handler):
     def emit(self, record):
         # Get corresponding Loguru level if it exists
         try:
             level = logger.level(record.levelname).name
         except ValueError:
             level = record.levelno
 
         # Find caller from where originated the logged message
-        frame, depth = logging.currentframe(), 2
+        frame, depth = logging.currentframe(), 6
         while frame.f_code.co_filename == logging.__file__:
             frame = frame.f_back
             depth += 1
         logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())
 
 
 def setting_log(log_name, multi_process=True):
@@ -35,16 +34,16 @@
 
     logging.root.handlers = [InterceptHandler()]
     for name in logging.root.manager.loggerDict.keys():
         logging.getLogger(name).handlers = []
         logging.getLogger(name).propagate = True
     logger_config = {
         "handlers": [
-            {"sink": sys.stdout},
-            {"sink": f"./Log/{log_name}", "enqueue": multi_process, "rotation": "100 MB"},
+            {"sink": sys.stdout, "level": "DEBUG"},
+            {"sink": f"./Log/{log_name}.log", "enqueue": multi_process, "rotation": "100 MB", "level": "INFO"},
         ],
     }
     logger.configure(**logger_config)
 
 
 def yaml_dump(data, filepath, rel_path=False, mode='w'):
     abs_path = relp(filepath, parents=1) if rel_path else filepath
```

### Comparing `openai_forward-0.1.7/openai_forward/openai.py` & `openai_forward-0.1.8/openai_forward/openai.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-from ._base import OpenaiBase
+from .base import OpenaiBase
 from .routers.schemas import OpenAIV1ChatCompletion
 from fastapi import Request
 from .config import setting_log
 
-setting_log(log_name="openai_forward.log")
+setting_log(log_name="openai_forward")
 
 
 class Openai(OpenaiBase):
     def __init__(self):
         if self.IP_BLACKLIST or self.IP_WHITELIST:
             self.validate_host = True
         else:
```

### Comparing `openai_forward-0.1.7/openai_forward/content/chat.py` & `openai_forward-0.1.8/openai_forward/content/chat.py`

 * *Files identical despite different names*

### Comparing `openai_forward-0.1.7/openai_forward/routers/schemas.py` & `openai_forward-0.1.8/openai_forward/routers/schemas.py`

 * *Files identical despite different names*

### Comparing `openai_forward-0.1.7/.gitignore` & `openai_forward-0.1.8/.gitignore`

 * *Files identical despite different names*

### Comparing `openai_forward-0.1.7/LICENSE` & `openai_forward-0.1.8/LICENSE`

 * *Files identical despite different names*

### Comparing `openai_forward-0.1.7/pyproject.toml` & `openai_forward-0.1.8/pyproject.toml`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 [build-system]
 requires = ["hatchling"]
 build-backend = "hatchling.build"
 
 [project]
 name = "openai_forward"
-description = "ğŸš€ Openai api forward Â· OpenAI æ¥å£è½¬å‘æœåŠ¡ Â· streaming forward"
+description = "ğŸš€ Openai api forward Â· OpenAI æ¥å£è½¬å‘æœåŠ¡ Â· stream forwarding"
 authors = [
     { name = "kunyuan", email = "beidongjiedeguang@gmail.com" },
 ]
 requires-python = ">=3.6"
 readme = "README.md"
 keywords = ["openai", "chatgpt", "openai-api", "openai-proxy", "forward", "streaming-api", "fastapi", "python"]
 classifiers = [
```

### Comparing `openai_forward-0.1.7/PKG-INFO` & `openai_forward-0.1.8/PKG-INFO`

 * *Files 27% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 Metadata-Version: 2.1
 Name: openai_forward
-Version: 0.1.7
-Summary: ğŸš€ Openai api forward Â· OpenAI æ¥å£è½¬å‘æœåŠ¡ Â· streaming forward
+Version: 0.1.8
+Summary: ğŸš€ Openai api forward Â· OpenAI æ¥å£è½¬å‘æœåŠ¡ Â· stream forwarding
 Project-URL: Homepage, https://github.com/beidongjiedeguang/openai-forward
 Project-URL: Documentation, https://github.com/beidongjiedeguang/openai-forward#openai-forward
 Project-URL: Issues, https://github.com/beidongjiedeguang/openai-forward/issues
 Project-URL: Source, https://github.com/beidongjiedeguang/openai-forward
 Author-email: kunyuan <beidongjiedeguang@gmail.com>
 License-File: LICENSE
 Keywords: chatgpt,fastapi,forward,openai,openai-api,openai-proxy,python,streaming-api
@@ -27,15 +27,15 @@
 Requires-Dist: revchatgpt; extra == 'chatgpt'
 Provides-Extra: edge
 Requires-Dist: edgegpt; extra == 'edge'
 Provides-Extra: ssl
 Requires-Dist: certbot; extra == 'ssl'
 Description-Content-Type: text/markdown
 
-[**ä¸­æ–‡**](./README_ZH.md) | **English**
+**ä¸­æ–‡** | [**English**](./README_EN.md)
 
 <h1 align="center">
     <br>
     OpenAI Forward
     <br>
 </h1>
 <p align="center">
@@ -62,182 +62,240 @@
     </a>
     <a href="https://pypi.org/project/openai_forward/">
         <img alt="pypi downloads" src="https://img.shields.io/pypi/dm/openai_forward">
     </a>
     <a href="https://codecov.io/gh/beidongjiedeguang/openai-forward">
         <img alt="codecov" src="https://codecov.io/gh/beidongjiedeguang/openai-forward/branch/dev/graph/badge.svg">
     </a>
-
 </p>
-This project is designed to solve the problem of some regions being unable to directly access OpenAI. The service is deployed on a server that can access the OpenAI API, and OpenAI requests are forwarded through the service, i.e. a reverse proxy service is set up. 
 
-Test access: https://caloi.top/openai/v1/chat/completions is equivalent to https://api.openai.com/v1/chat/completions  
-Or, to put it another way, https://caloi.top/openai is equivalent to https://api.openai.com.
+
+
+æœ¬é¡¹ç›®ç”¨äºè§£å†³ä¸€äº›åœ°åŒºæ— æ³•ç›´æ¥è®¿é—®OpenAIçš„é—®é¢˜ï¼Œå°†è¯¥æœåŠ¡éƒ¨ç½²åœ¨å¯ä»¥æ­£å¸¸è®¿é—®openai
+apiçš„æœåŠ¡å™¨ä¸Šï¼Œé€šè¿‡è¯¥æœåŠ¡è½¬å‘OpenAIçš„è¯·æ±‚ã€‚å³æ­å»ºåå‘ä»£ç†æœåŠ¡  
+æµ‹è¯•è®¿é—®ï¼šhttps://caloi.top/openai/v1/chat/completions å°†ç­‰ä»·äº https://api.openai.com/v1/chat/completions  
+æˆ–è€…è¯´ https://caloi.top/openai ç­‰ä»·äº https://api.openai.com
 
 # Table of Contents
 
 - [Features](#Features)
-- [Usage](#Usage)
-- [Deploy](#Deploy)
-- [Service Usage](#Service-Usage)
-- [Configuration](#Configuration)
-- [Chat Log](#Chat-log)
+- [åº”ç”¨](#åº”ç”¨)
+- [å®‰è£…éƒ¨ç½²](#å®‰è£…éƒ¨ç½²)
+- [æœåŠ¡è°ƒç”¨](#æœåŠ¡è°ƒç”¨)
+- [é…ç½®é€‰é¡¹](#é…ç½®é€‰é¡¹)
+- [èŠå¤©æ—¥å¿—](#èŠå¤©æ—¥å¿—)
+- [é«˜çº§é…ç½®](#é«˜çº§é…ç½®)
 
 # Features
 
-- [x] Supports forwarding of all OpenAI interfaces
-- [x] Request IP verification
-- [x] Streaming Response
-- [x] Supports default API key (cyclic call with multiple API keys)
-- [x] pip installation and deployment
-- [x] Docker deployment
-- [x] Support for multiple worker processes
-- [x] Support for specifying the forwarding routing prefix
+- [x] æ”¯æŒè½¬å‘OpenAIæ‰€æœ‰æ¥å£
+- [x] æ”¯æŒæµå¼å“åº”
+- [x] å®æ—¶è®°å½•èŠå¤©è®°å½•(åŒ…æ‹¬æµå¼å“åº”çš„èŠå¤©å†…å®¹)
+- [x] æ”¯æŒé»˜è®¤openai api key(å¤šapi key å¾ªç¯è°ƒç”¨)
+- [x] è½¬å‘api key (åœ¨å·²è®¾ç½®é»˜è®¤openai api keyæƒ…å†µä¸‹ä½¿ç”¨)
+- [x] dockeréƒ¨ç½²
+- [x] æ”¯æŒæŒ‡å®šè½¬å‘è·¯ç”±å‰ç¼€
+- [x] æ”¯æŒè¯·æ±‚IPéªŒè¯
 
-# Usage
+# åº”ç”¨
 
-> Here, the proxy address set up by the individual, https://caloi.top/openai, is used as an example
+> è¿™é‡Œä»¥ä¸ªäººä½¿ç”¨è¯¥é¡¹ç›®æ­å»ºå¥½çš„ä»£ç†æœåŠ¡ https://caloi.top/openai ä¸ºä¾‹
 
-### Using in a module
+### [caloi.top](https://caloi.top)
 
+åŸºäºå¼€æºé¡¹ç›®[ChatGPT-Next-Web](https://github.com/Yidadaa/ChatGPT-Next-Web)æ­å»ºè‡ªå·±çš„chatgptæœåŠ¡  
+æ›¿æ¢dockerå¯åŠ¨å‘½ä»¤ä¸­çš„ `BASE_URL`ä¸ºæˆ‘ä»¬è‡ªå·±æ­å»ºçš„ä»£ç†æœåŠ¡åœ°å€
 
-**Python**
+```bash 
+docker run -d \
+    -p 3000:3000 \
+    -e OPENAI_API_KEY="sk-******" \
+    -e BASE_URL="caloi.top/openai" \
+    -e CODE="<your password>" \
+    yidadaa/chatgpt-next-web 
+``` 
 
-```diff
-  import openai
-+ openai.api_base = "https://caloi.top/openai/v1"
-  openai.api_key = "sk-******"
-```
+è®¿é—® https://caloi.top ã€‚è®¿é—®å¯†ç ä¸º `beidongjiedeguang`
+
+### åœ¨æ¨¡å—ä¸­ä½¿ç”¨
 
 **JS/TS**
 
 ```diff
   import { Configuration } from "openai";
   
   const configuration = new Configuration({
 + basePath: "https://caloi.top/openai/v1",
   apiKey: "sk-******",
   });
 ```
 
+**Python**
+
+```diff
+  import openai
++ openai.api_base = "https://caloi.top/openai/v1"
+  openai.api_key = "sk-******"
+```
 
 ### Image Generation (DALL-E):
 
-```bash 
-curl --location 'https://caloi.top/openai/v1/images/generations' \ 
---header 'Authorization: Bearer sk-******' \ 
---header 'Content-Type: application/json' \ 
---data '{ 
-    "prompt": "A photo of a cat", 
-    "n": 1, 
+```bash
+curl --location 'https://caloi.top/openai/v1/images/generations' \
+--header 'Authorization: Bearer sk-******' \
+--header 'Content-Type: application/json' \
+--data '{
+    "prompt": "A photo of a cat",
+    "n": 1,
     "size": "512x512"
-}' 
-``` 
+}'
+```
 
-### [chatgpt-web](https://github.com/Chanzhaoyu/chatgpt-web)
+# å®‰è£…éƒ¨ç½²
 
-Modify the `OPENAI_API_BASE_URL` in [Docker Compose](https://github.com/Chanzhaoyu/chatgpt-web#docker-compose) to the
-address of the proxy service we set up:
+æä¾›3ç§æœåŠ¡éƒ¨ç½²æ–¹å¼,é€‰æ‹©ä¸€ç§å³å¯
 
-```bash 
-OPENAI_API_BASE_URL: https://caloi.top/openai 
-``` 
+## pip
+pipçš„å®‰è£…æ–¹å¼ç›®å‰åœ¨ä½¿ç”¨nginxåå‘ä»£ç†æ—¶å­˜åœ¨Bug, å»ºè®®ä½¿ç”¨Dockeræ–¹å¼éƒ¨ç½²ã€‚  
+**å®‰è£…**
 
-### [ChatGPT-Next-Web](https://github.com/Yidadaa/ChatGPT-Next-Web)
-
-Replace `BASE_URL` in the docker startup command with the address of the proxy service we set up:
+```bash
+pip install openai-forward
+```
 
-```bash 
-docker run -d -p 3000:3000 -e OPENAI_API_KEY="sk-******" -e CODE="<your password>" -e BASE_URL="caloi.top/openai" yidadaa/chatgpt-next-web 
-``` 
+**è¿è¡Œè½¬å‘æœåŠ¡**  
+å¯é€šè¿‡`--port`æŒ‡å®šç«¯å£å·ï¼Œé»˜è®¤ä¸º`8000`ï¼Œå¯é€šè¿‡`--workers`æŒ‡å®šå·¥ä½œè¿›ç¨‹æ•°ï¼Œé»˜è®¤ä¸º`1`
 
+```bash
+openai_forward run --port=9999 --workers=1
+```
 
-# Deploy
+æœåŠ¡å°±æ­å»ºå®Œæˆäº†ï¼Œä½¿ç”¨æ–¹å¼åªéœ€å°†`https://api.openai.com` æ›¿æ¢ä¸ºæœåŠ¡æ‰€åœ¨ç«¯å£`http://{ip}:{port}` å³å¯ã€‚
 
-Two deployment methods are provided, just choose one.
+å½“ç„¶ä¹Ÿå¯ä»¥å°† OPENAI_API_KEY ä½œä¸ºç¯å¢ƒå˜é‡ä¼ å…¥ä½œä¸ºé»˜è®¤api keyï¼Œ è¿™æ ·å®¢æˆ·ç«¯åœ¨è¯·æ±‚ç›¸å…³è·¯ç”±æ—¶å¯ä»¥æ— éœ€åœ¨Headerä¸­ä¼ å…¥Authorizationã€‚
+å¸¦é»˜è®¤api keyçš„å¯åŠ¨æ–¹å¼ï¼š
 
-## Use `pip`  (recommended)
+```bash
+OPENAI_API_KEY="sk-xxx" openai_forward run --port=9999 --workers=1
+```
 
-**Installation**
+æ³¨: å¦‚æœæ—¢å­˜åœ¨é»˜è®¤api keyåˆåœ¨è¯·æ±‚å¤´ä¸­ä¼ å…¥äº†api keyï¼Œåˆ™ä»¥è¯·æ±‚å¤´ä¸­çš„api keyä¼šè¦†ç›–é»˜è®¤api key.
 
-```bash 
-pip install openai-forward 
-``` 
+## Docker (æ¨è)
 
-**Run forwarding service**
-The port number can be specified through `--port`, which defaults to `8000`, and the number of worker processes can be
-specified through `--workers`, which defaults to `1`.
+```bash
+docker run --name="openai-forward" -d -p 9999:8000 beidongjiedeguang/openai-forward:latest 
+```
 
-```bash 
-openai_forward run --port=9999 --workers=1 
-``` 
+å°†æ˜ å°„å®¿ä¸»æœºçš„9999ç«¯å£ï¼Œé€šè¿‡`http://{ip}:9999`è®¿é—®æœåŠ¡ã€‚  
+æ³¨ï¼šåŒæ ·å¯ä»¥åœ¨å¯åŠ¨å‘½ä»¤ä¸­é€šè¿‡-eä¼ å…¥ç¯å¢ƒå˜é‡OPENAI_API_KEY=sk-xxxä½œä¸ºé»˜è®¤api key
 
-The service is now set up, and the usage is to replace `https://api.openai.com` with the port number of the
-service `http://{ip}:{port}`.
+## æºç éƒ¨ç½²
 
-Of course, OPENAI_API_KEY can also be passed in as an environment variable as the default API key, so that the client
-does not need to pass in the Authorization in the header when requesting the relevant route.
-Startup command with default API key:
+```bash
+git clone https://github.com/beidongjiedeguang/openai-forward.git --depth=1
+cd openai-forward
+```
 
-```bash 
-OPENAI_API_KEY="sk-xxx" openai_forward run --port=9999 --workers=1 
-``` 
+**ä½¿ç”¨ docker**
 
-Note: If both the default API key and the API key passed in the request header exist, the API key in the request header
-will override the default API key.
+```bash
+docker-compose up
+```
 
-## Use Docker
+**æˆ–ä½¿ç”¨pip**
 
-```bash 
-docker run --name="openai-forward" -d -p 9999:8000 beidongjiedeguang/openai-forward:latest 
-``` 
+```bash
+pip install -e .
+openai-forward run 
+```
 
-The 9999 port of the host is mapped, and the service can be accessed through `http://{ip}:9999`.
-Note: You can also pass in the environment variable OPENAI_API_KEY=sk-xxx as the default API key in the startup command.
+# æœåŠ¡è°ƒç”¨
 
-# Service Usage
+æ›¿æ¢openaiçš„apiåœ°å€ä¸ºè¯¥æœåŠ¡çš„åœ°å€å³å¯ï¼Œå¦‚ï¼š
 
-Simply replace the OpenAI API address with the address of the service we set up, such as `Chat Completion`
-```bash 
-https://api.openai.com/v1/chat/completions 
-``` 
+```bash
+https://api.openai.com/v1/chat/completions
+```
 
-Replace with
+æ›¿æ¢ä¸º
 
-```bash 
-http://{ip}:{port}/v1/chat/completions 
+```bash
+http://{ip}:{port}/v1/chat/completions
 ```
 
-# Configuration
+# é…ç½®é€‰é¡¹
 
-**`openai-forward run` Parameter Configuration Options**
+**`openai-forward run`å‚æ•°é…ç½®é¡¹**
 
-| Configuration Option | Description | Default Value |
+| é…ç½®é¡¹       | è¯´æ˜ | é»˜è®¤å€¼ |
 |-----------| --- | :---: |
-| --port    | Service port number | 8000 |
-| --workers | Number of worker processes | 1 |
+| --port    | æœåŠ¡ç«¯å£å· | 8000 |
+| --workers | å·¥ä½œè¿›ç¨‹æ•° | 1 |
+
+**ç¯å¢ƒå˜é‡é…ç½®é¡¹**  
+å‚è€ƒé¡¹ç›®æ ¹ç›®å½•ä¸‹`.env`æ–‡ä»¶
 
-**Environment Variable Configuration Options**  
-refer to the `.env` file in the project root directory
+| ç¯å¢ƒå˜é‡            | è¯´æ˜                                                              |           é»˜è®¤å€¼            |
+|-----------------|-----------------------------------------------------------------|:------------------------:|
+| OPENAI_API_KEY  | é»˜è®¤openai api keyï¼Œæ”¯æŒå¤šä¸ªé»˜è®¤api key, ä»¥ `sk-` å¼€å¤´ï¼Œ ä»¥ç©ºæ ¼åˆ†å‰²      |            æ—              |
+| FORWARD_KEY     | å…è®¸è°ƒç”¨æ–¹ä½¿ç”¨è¯¥keyä»£æ›¿openai api keyï¼Œæ”¯æŒå¤šä¸ªforward key, ä»¥`fk-` å¼€å¤´, ä»¥ç©ºæ ¼åˆ†å‰² |      æ—              |
+| OPENAI_BASE_URL | è½¬å‘base url                                                      | `https://api.openai.com` |
+| LOG_CHAT        | æ˜¯å¦è®°å½•èŠå¤©å†…å®¹                                                        |          `true`          |
+| ROUTE_PREFIX    | è·¯ç”±å‰ç¼€                                                            |            æ—              |
+| IP_WHITELIST    | ipç™½åå•, ç©ºæ ¼åˆ†å¼€                                                     |           æ—             |
+| IP_BLACKLIST    | ipé»‘åå•, ç©ºæ ¼åˆ†å¼€                                                     |           æ—             | 
+
+# èŠå¤©æ—¥å¿—
+
+ä¿å­˜è·¯å¾„åœ¨å½“å‰ç›®å½•ä¸‹çš„`Log/`è·¯å¾„ä¸­ã€‚  
+èŠå¤©æ—¥å¿—ä»¥ `chat_`å¼€å¤´, é»˜è®¤æ¯5è½®å¯¹è¯å†™å…¥ä¸€æ¬¡æ–‡ä»¶    
+è®°å½•æ ¼å¼ä¸º
 
-| Environment Variable  | Description | Default Value |
-|-----------------|------------|:------------------------:|
-| OPENAI_API_KEY  | Default API key, supports multiple default API keys separated by space. | None |
-| OPENAI_BASE_URL | Forwarding base URL | `https://api.openai.com` |
-|LOG_CHAT| Whether to log chat content | `true` |
-|ROUTE_PREFIX| Route prefix | None |
-| IP_WHITELIST    | IP whitelist, separated by space. | None |
-| IP_BLACKLIST    | IP blacklist, separated by space. | None |
-
-# Chat Log
-The saved path is in the `Log/` directory under the current directory.  
-The chat log starts with `chat_` and is written to the file every 5 rounds by default.  
-The recording format is as follows:
 ```text
 {'host': xxx, 'model': xxx, 'message': [{'user': xxx}, {'assistant': xxx}]}
 {'assistant': xxx}
 
 {'host': ...}
 {'assistant': ...}
 
 ...
-```
+```
+
+# é«˜çº§é…ç½®
+
+**è®¾ç½®api_keyä¸ºè‡ªå·±è®¾ç½®çš„forward key**  
+éœ€è¦é…ç½® OPENAI_API_KEY å’Œ FORWARD_KEY, ä¾‹å¦‚
+
+```bash
+OPENAI_API_KEY=sk-*******
+FORWARD_KEY=fk-****** # è¿™é‡Œfk-tokenç”±æˆ‘ä»¬è‡ªå·±å®šä¹‰
+```
+è¿™é‡Œæˆ‘ä»¬é…ç½®äº†FORWARD_KEYä¸º`fk-******`, é‚£ä¹ˆåé¢å®¢æˆ·ç«¯åœ¨è°ƒç”¨æ—¶åªéœ€è®¾ç½®OPENAI_API_KEYä¸ºæˆ‘ä»¬è‡ªå®šä¹‰çš„`fk-******` å³å¯ã€‚  
+è¿™æ ·çš„å¥½å¤„æ˜¯åœ¨ä½¿ç”¨ä¸€äº›éœ€è¦è¾“å…¥OPENAI_API_KEYçš„ç¬¬ä¸‰æ–¹åº”ç”¨æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`fk-******`æ­é…proxyä½¿ç”¨ï¼ˆå¦‚ä¸‹é¢çš„ä¾‹å­ï¼‰ è€Œæ— éœ€æ‹…å¿ƒOPENAI_API_KEYè¢«æ³„éœ²ã€‚
+
+**ç”¨ä¾‹:**
+```bash
+curl https://caloi.top/openai/v1/chat/completions \
+  -H "Content-Type: application/json" \
+  -H "Authorization: Bearer fk-******" \
+  -d '{
+    "model": "gpt-3.5-turbo",
+    "messages": [{"role": "user", "content": "Hello!"}]
+  }'
+```
+**Python**
+```diff
+  import openai
++ openai.api_base = "https://caloi.top/openai/v1"
+- openai.api_key = "sk-******"
++ openai.api_key = "fk-******"
+```
+**Web application**
+```bash 
+docker run -d \
+    -p 3000:3000 \
+    -e OPENAI_API_KEY="fk-******" \
+    -e BASE_URL="caloi.top/openai" \
+    -e CODE="<your password>" \
+    yidadaa/chatgpt-next-web 
+```
```

#### html2text {}

```diff
@@ -1,9 +1,9 @@
-Metadata-Version: 2.1 Name: openai_forward Version: 0.1.7 Summary: Ã°ÂŸÂšÂ€ Openai
-api forward Ã‚Â· OpenAI Ã¦ÂÂ¥Ã¥ÂÂ£Ã¨Â½Â¬Ã¥ÂÂ‘Ã¦ÂœÂÃ¥ÂŠÂ¡ Ã‚Â· streaming forward Project-URL:
+Metadata-Version: 2.1 Name: openai_forward Version: 0.1.8 Summary: Ã°ÂŸÂšÂ€ Openai
+api forward Ã‚Â· OpenAI Ã¦ÂÂ¥Ã¥ÂÂ£Ã¨Â½Â¬Ã¥ÂÂ‘Ã¦ÂœÂÃ¥ÂŠÂ¡ Ã‚Â· stream forwarding Project-URL:
 Homepage, https://github.com/beidongjiedeguang/openai-forward Project-URL:
 Documentation, https://github.com/beidongjiedeguang/openai-forward#openai-
 forward Project-URL: Issues, https://github.com/beidongjiedeguang/openai-
 forward/issues Project-URL: Source, https://github.com/beidongjiedeguang/
 openai-forward Author-email: kunyuan
 gmail.com> License-File: LICENSE Keywords:
 chatgpt,fastapi,forward,openai,openai-api,openai-proxy,python,streaming-api
@@ -11,83 +11,102 @@
 System :: OS Independent Classifier: Programming Language :: Python :: 3
 Requires-Python: >=3.6 Requires-Dist: fastapi Requires-Dist: httpx Requires-
 Dist: loguru Requires-Dist: orjson Requires-Dist: python-dotenv Requires-Dist:
 pytz Requires-Dist: sparrow-python>=0.1.2 Requires-Dist: uvicorn Provides-
 Extra: bard Requires-Dist: googlebard; extra == 'bard' Provides-Extra: chatgpt
 Requires-Dist: revchatgpt; extra == 'chatgpt' Provides-Extra: edge Requires-
 Dist: edgegpt; extra == 'edge' Provides-Extra: ssl Requires-Dist: certbot;
-extra == 'ssl' Description-Content-Type: text/markdown [**Ã¤Â¸Â­Ã¦Â–Â‡**](./
-README_ZH.md) | **English**
+extra == 'ssl' Description-Content-Type: text/markdown **Ã¤Â¸Â­Ã¦Â–Â‡** |
+[**English**](./README_EN.md)
                                     ******
                                 OpenAI Forward
                                      ******
                         OpenAI API Ã¦ÂÂ¥Ã¥ÂÂ£Ã¨Â½Â¬Ã¥ÂÂ‘Ã¦ÂœÂÃ¥ÂŠÂ¡
                 The fastest way to deploy openai api forwarding
  [PyPI_version] [License] [Release_(latest_by_date)] [GitHub_repo_size] [docer
                 image_size] [tests] [pypi_downloads] [codecov]
-This project is designed to solve the problem of some regions being unable to
-directly access OpenAI. The service is deployed on a server that can access the
-OpenAI API, and OpenAI requests are forwarded through the service, i.e. a
-reverse proxy service is set up. Test access: https://caloi.top/openai/v1/chat/
-completions is equivalent to https://api.openai.com/v1/chat/completions Or, to
-put it another way, https://caloi.top/openai is equivalent to https://
-api.openai.com. # Table of Contents - [Features](#Features) - [Usage](#Usage) -
-[Deploy](#Deploy) - [Service Usage](#Service-Usage) - [Configuration]
-(#Configuration) - [Chat Log](#Chat-log) # Features - [x] Supports forwarding
-of all OpenAI interfaces - [x] Request IP verification - [x] Streaming Response
-- [x] Supports default API key (cyclic call with multiple API keys) - [x] pip
-installation and deployment - [x] Docker deployment - [x] Support for multiple
-worker processes - [x] Support for specifying the forwarding routing prefix #
-Usage > Here, the proxy address set up by the individual, https://caloi.top/
-openai, is used as an example ### Using in a module **Python** ```diff import
-openai + openai.api_base = "https://caloi.top/openai/v1" openai.api_key = "sk-
-******" ``` **JS/TS** ```diff import { Configuration } from "openai"; const
-configuration = new Configuration({ + basePath: "https://caloi.top/openai/v1",
-apiKey: "sk-******", }); ``` ### Image Generation (DALL-E): ```bash curl --
-location 'https://caloi.top/openai/v1/images/generations' \ --header
+Ã¦ÂœÂ¬Ã©Â¡Â¹Ã§Â›Â®Ã§Â”Â¨Ã¤ÂºÂÃ¨Â§Â£Ã¥Â†Â³Ã¤Â¸Â€Ã¤ÂºÂ›Ã¥ÂœÂ°Ã¥ÂŒÂºÃ¦Â—Â Ã¦Â³Â•Ã§Â›Â´Ã¦ÂÂ¥Ã¨Â®Â¿Ã©Â—Â®OpenAIÃ§ÂšÂ„Ã©Â—Â®Ã©Â¢Â˜Ã¯Â¼ÂŒÃ¥Â°Â†Ã¨Â¯Â¥Ã¦ÂœÂÃ¥ÂŠÂ¡Ã©ÂƒÂ¨Ã§Â½Â²Ã¥ÂœÂ¨Ã¥ÂÂ¯Ã¤Â»Â¥Ã¦Â­Â£Ã¥Â¸Â¸Ã¨Â®Â¿Ã©Â—Â®openai
+apiÃ§ÂšÂ„Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¥Â™Â¨Ã¤Â¸ÂŠÃ¯Â¼ÂŒÃ©Â€ÂšÃ¨Â¿Â‡Ã¨Â¯Â¥Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¨Â½Â¬Ã¥ÂÂ‘OpenAIÃ§ÂšÂ„Ã¨Â¯Â·Ã¦Â±Â‚Ã£Â€Â‚Ã¥ÂÂ³Ã¦ÂÂ­Ã¥Â»ÂºÃ¥ÂÂÃ¥ÂÂ‘Ã¤Â»Â£Ã§ÂÂ†Ã¦ÂœÂÃ¥ÂŠÂ¡
+Ã¦ÂµÂ‹Ã¨Â¯Â•Ã¨Â®Â¿Ã©Â—Â®Ã¯Â¼Âšhttps://caloi.top/openai/v1/chat/completions Ã¥Â°Â†Ã§Â­Â‰Ã¤Â»Â·Ã¤ÂºÂ https:
+//api.openai.com/v1/chat/completions Ã¦ÂˆÂ–Ã¨Â€Â…Ã¨Â¯Â´ https://caloi.top/openai
+Ã§Â­Â‰Ã¤Â»Â·Ã¤ÂºÂ https://api.openai.com # Table of Contents - [Features](#Features) -
+[Ã¥ÂºÂ”Ã§Â”Â¨](#Ã¥ÂºÂ”Ã§Â”Â¨) - [Ã¥Â®Â‰Ã¨Â£Â…Ã©ÂƒÂ¨Ã§Â½Â²](#Ã¥Â®Â‰Ã¨Â£Â…Ã©ÂƒÂ¨Ã§Â½Â²) - [Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¨Â°ÂƒÃ§Â”Â¨]
+(#Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¨Â°ÂƒÃ§Â”Â¨) - [Ã©Â…ÂÃ§Â½Â®Ã©Â€Â‰Ã©Â¡Â¹](#Ã©Â…ÂÃ§Â½Â®Ã©Â€Â‰Ã©Â¡Â¹) - [Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â—](#Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â—)
+- [Ã©Â«Â˜Ã§ÂºÂ§Ã©Â…ÂÃ§Â½Â®](#Ã©Â«Â˜Ã§ÂºÂ§Ã©Â…ÂÃ§Â½Â®) # Features - [x] Ã¦Â”Â¯Ã¦ÂŒÂÃ¨Â½Â¬Ã¥ÂÂ‘OpenAIÃ¦Â‰Â€Ã¦ÂœÂ‰Ã¦ÂÂ¥Ã¥ÂÂ£
+- [x] Ã¦Â”Â¯Ã¦ÂŒÂÃ¦ÂµÂÃ¥Â¼ÂÃ¥Â“ÂÃ¥ÂºÂ” - [x] Ã¥Â®ÂÃ¦Â—Â¶Ã¨Â®Â°Ã¥Â½Â•Ã¨ÂÂŠÃ¥Â¤Â©Ã¨Â®Â°Ã¥Â½Â•
+(Ã¥ÂŒÂ…Ã¦Â‹Â¬Ã¦ÂµÂÃ¥Â¼ÂÃ¥Â“ÂÃ¥ÂºÂ”Ã§ÂšÂ„Ã¨ÂÂŠÃ¥Â¤Â©Ã¥Â†Â…Ã¥Â®Â¹) - [x] Ã¦Â”Â¯Ã¦ÂŒÂÃ©Â»Â˜Ã¨Â®Â¤openai api key(Ã¥Â¤Âšapi key
+Ã¥Â¾ÂªÃ§ÂÂ¯Ã¨Â°ÂƒÃ§Â”Â¨) - [x] Ã¨Â½Â¬Ã¥ÂÂ‘api key (Ã¥ÂœÂ¨Ã¥Â·Â²Ã¨Â®Â¾Ã§Â½Â®Ã©Â»Â˜Ã¨Â®Â¤openai api
+keyÃ¦ÂƒÂ…Ã¥Â†ÂµÃ¤Â¸Â‹Ã¤Â½Â¿Ã§Â”Â¨) - [x] dockerÃ©ÂƒÂ¨Ã§Â½Â² - [x] Ã¦Â”Â¯Ã¦ÂŒÂÃ¦ÂŒÂ‡Ã¥Â®ÂšÃ¨Â½Â¬Ã¥ÂÂ‘Ã¨Â·Â¯Ã§Â”Â±Ã¥Â‰ÂÃ§Â¼Â€ -
+[x] Ã¦Â”Â¯Ã¦ÂŒÂÃ¨Â¯Â·Ã¦Â±Â‚IPÃ©ÂªÂŒÃ¨Â¯Â # Ã¥ÂºÂ”Ã§Â”Â¨ >
+Ã¨Â¿Â™Ã©Â‡ÂŒÃ¤Â»Â¥Ã¤Â¸ÂªÃ¤ÂºÂºÃ¤Â½Â¿Ã§Â”Â¨Ã¨Â¯Â¥Ã©Â¡Â¹Ã§Â›Â®Ã¦ÂÂ­Ã¥Â»ÂºÃ¥Â¥Â½Ã§ÂšÂ„Ã¤Â»Â£Ã§ÂÂ†Ã¦ÂœÂÃ¥ÂŠÂ¡ https://caloi.top/openai
+Ã¤Â¸ÂºÃ¤Â¾Â‹ ### [caloi.top](https://caloi.top) Ã¥ÂŸÂºÃ¤ÂºÂÃ¥Â¼Â€Ã¦ÂºÂÃ©Â¡Â¹Ã§Â›Â®[ChatGPT-Next-Web]
+(https://github.com/Yidadaa/ChatGPT-Next-Web)Ã¦ÂÂ­Ã¥Â»ÂºÃ¨Â‡ÂªÃ¥Â·Â±Ã§ÂšÂ„chatgptÃ¦ÂœÂÃ¥ÂŠÂ¡
+Ã¦Â›Â¿Ã¦ÂÂ¢dockerÃ¥ÂÂ¯Ã¥ÂŠÂ¨Ã¥Â‘Â½Ã¤Â»Â¤Ã¤Â¸Â­Ã§ÂšÂ„
+`BASE_URL`Ã¤Â¸ÂºÃ¦ÂˆÂ‘Ã¤Â»Â¬Ã¨Â‡ÂªÃ¥Â·Â±Ã¦ÂÂ­Ã¥Â»ÂºÃ§ÂšÂ„Ã¤Â»Â£Ã§ÂÂ†Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¥ÂœÂ°Ã¥ÂÂ€ ```bash docker run -d \ -
+p 3000:3000 \ -e OPENAI_API_KEY="sk-******" \ -e BASE_URL="caloi.top/openai" \
+-e CODE="" \ yidadaa/chatgpt-next-web ``` Ã¨Â®Â¿Ã©Â—Â® https://caloi.top
+Ã£Â€Â‚Ã¨Â®Â¿Ã©Â—Â®Ã¥Â¯Â†Ã§Â ÂÃ¤Â¸Âº `beidongjiedeguang` ### Ã¥ÂœÂ¨Ã¦Â¨Â¡Ã¥ÂÂ—Ã¤Â¸Â­Ã¤Â½Â¿Ã§Â”Â¨ **JS/TS** ```diff
+import { Configuration } from "openai"; const configuration = new Configuration
+({ + basePath: "https://caloi.top/openai/v1", apiKey: "sk-******", }); ```
+**Python** ```diff import openai + openai.api_base = "https://caloi.top/openai/
+v1" openai.api_key = "sk-******" ``` ### Image Generation (DALL-E): ```bash
+curl --location 'https://caloi.top/openai/v1/images/generations' \ --header
 'Authorization: Bearer sk-******' \ --header 'Content-Type: application/json' \
---data '{ "prompt": "A photo of a cat", "n": 1, "size": "512x512" }' ``` ###
-[chatgpt-web](https://github.com/Chanzhaoyu/chatgpt-web) Modify the
-`OPENAI_API_BASE_URL` in [Docker Compose](https://github.com/Chanzhaoyu/
-chatgpt-web#docker-compose) to the address of the proxy service we set up:
-```bash OPENAI_API_BASE_URL: https://caloi.top/openai ``` ### [ChatGPT-Next-
-Web](https://github.com/Yidadaa/ChatGPT-Next-Web) Replace `BASE_URL` in the
-docker startup command with the address of the proxy service we set up: ```bash
-docker run -d -p 3000:3000 -e OPENAI_API_KEY="sk-******" -e CODE="" -
-e BASE_URL="caloi.top/openai" yidadaa/chatgpt-next-web ``` # Deploy Two
-deployment methods are provided, just choose one. ## Use `pip` (recommended)
-**Installation** ```bash pip install openai-forward ``` **Run forwarding
-service** The port number can be specified through `--port`, which defaults to
-`8000`, and the number of worker processes can be specified through `--
-workers`, which defaults to `1`. ```bash openai_forward run --port=9999 --
-workers=1 ``` The service is now set up, and the usage is to replace `https://
-api.openai.com` with the port number of the service `http://{ip}:{port}`. Of
-course, OPENAI_API_KEY can also be passed in as an environment variable as the
-default API key, so that the client does not need to pass in the Authorization
-in the header when requesting the relevant route. Startup command with default
-API key: ```bash OPENAI_API_KEY="sk-xxx" openai_forward run --port=9999 --
-workers=1 ``` Note: If both the default API key and the API key passed in the
-request header exist, the API key in the request header will override the
-default API key. ## Use Docker ```bash docker run --name="openai-forward" -d -
-p 9999:8000 beidongjiedeguang/openai-forward:latest ``` The 9999 port of the
-host is mapped, and the service can be accessed through `http://{ip}:9999`.
-Note: You can also pass in the environment variable OPENAI_API_KEY=sk-xxx as
-the default API key in the startup command. # Service Usage Simply replace the
-OpenAI API address with the address of the service we set up, such as `Chat
-Completion` ```bash https://api.openai.com/v1/chat/completions ``` Replace with
-```bash http://{ip}:{port}/v1/chat/completions ``` # Configuration **`openai-
-forward run` Parameter Configuration Options** | Configuration Option |
-Description | Default Value | |-----------| --- | :---: | | --port | Service
-port number | 8000 | | --workers | Number of worker processes | 1 |
-**Environment Variable Configuration Options** refer to the `.env` file in the
-project root directory | Environment Variable | Description | Default Value |
-|-----------------|------------|:------------------------:| | OPENAI_API_KEY |
-Default API key, supports multiple default API keys separated by space. | None
-| | OPENAI_BASE_URL | Forwarding base URL | `https://api.openai.com` |
-|LOG_CHAT| Whether to log chat content | `true` | |ROUTE_PREFIX| Route prefix |
-None | | IP_WHITELIST | IP whitelist, separated by space. | None | |
-IP_BLACKLIST | IP blacklist, separated by space. | None | # Chat Log The saved
-path is in the `Log/` directory under the current directory. The chat log
-starts with `chat_` and is written to the file every 5 rounds by default. The
-recording format is as follows: ```text {'host': xxx, 'model': xxx, 'message':
-[{'user': xxx}, {'assistant': xxx}]} {'assistant': xxx} {'host': ...}
-{'assistant': ...} ... ```
+--data '{ "prompt": "A photo of a cat", "n": 1, "size": "512x512" }' ``` #
+Ã¥Â®Â‰Ã¨Â£Â…Ã©ÂƒÂ¨Ã§Â½Â² Ã¦ÂÂÃ¤Â¾Â›3Ã§Â§ÂÃ¦ÂœÂÃ¥ÂŠÂ¡Ã©ÂƒÂ¨Ã§Â½Â²Ã¦Â–Â¹Ã¥Â¼Â,Ã©Â€Â‰Ã¦Â‹Â©Ã¤Â¸Â€Ã§Â§ÂÃ¥ÂÂ³Ã¥ÂÂ¯ ## pip
+pipÃ§ÂšÂ„Ã¥Â®Â‰Ã¨Â£Â…Ã¦Â–Â¹Ã¥Â¼ÂÃ§Â›Â®Ã¥Â‰ÂÃ¥ÂœÂ¨Ã¤Â½Â¿Ã§Â”Â¨nginxÃ¥ÂÂÃ¥ÂÂ‘Ã¤Â»Â£Ã§ÂÂ†Ã¦Â—Â¶Ã¥Â­Â˜Ã¥ÂœÂ¨Bug,
+Ã¥Â»ÂºÃ¨Â®Â®Ã¤Â½Â¿Ã§Â”Â¨DockerÃ¦Â–Â¹Ã¥Â¼ÂÃ©ÂƒÂ¨Ã§Â½Â²Ã£Â€Â‚ **Ã¥Â®Â‰Ã¨Â£Â…** ```bash pip install openai-forward
+``` **Ã¨Â¿ÂÃ¨Â¡ÂŒÃ¨Â½Â¬Ã¥ÂÂ‘Ã¦ÂœÂÃ¥ÂŠÂ¡** Ã¥ÂÂ¯Ã©Â€ÂšÃ¨Â¿Â‡`--
+port`Ã¦ÂŒÂ‡Ã¥Â®ÂšÃ§Â«Â¯Ã¥ÂÂ£Ã¥ÂÂ·Ã¯Â¼ÂŒÃ©Â»Â˜Ã¨Â®Â¤Ã¤Â¸Âº`8000`Ã¯Â¼ÂŒÃ¥ÂÂ¯Ã©Â€ÂšÃ¨Â¿Â‡`--
+workers`Ã¦ÂŒÂ‡Ã¥Â®ÂšÃ¥Â·Â¥Ã¤Â½ÂœÃ¨Â¿Â›Ã§Â¨Â‹Ã¦Â•Â°Ã¯Â¼ÂŒÃ©Â»Â˜Ã¨Â®Â¤Ã¤Â¸Âº`1` ```bash openai_forward run --
+port=9999 --workers=1 ```
+Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¥Â°Â±Ã¦ÂÂ­Ã¥Â»ÂºÃ¥Â®ÂŒÃ¦ÂˆÂÃ¤ÂºÂ†Ã¯Â¼ÂŒÃ¤Â½Â¿Ã§Â”Â¨Ã¦Â–Â¹Ã¥Â¼ÂÃ¥ÂÂªÃ©ÂœÂ€Ã¥Â°Â†`https://api.openai.com`
+Ã¦Â›Â¿Ã¦ÂÂ¢Ã¤Â¸ÂºÃ¦ÂœÂÃ¥ÂŠÂ¡Ã¦Â‰Â€Ã¥ÂœÂ¨Ã§Â«Â¯Ã¥ÂÂ£`http://{ip}:{port}` Ã¥ÂÂ³Ã¥ÂÂ¯Ã£Â€Â‚ Ã¥Â½Â“Ã§Â„Â¶Ã¤Â¹ÂŸÃ¥ÂÂ¯Ã¤Â»Â¥Ã¥Â°Â†
+OPENAI_API_KEY Ã¤Â½ÂœÃ¤Â¸ÂºÃ§ÂÂ¯Ã¥Â¢ÂƒÃ¥ÂÂ˜Ã©Â‡ÂÃ¤Â¼Â Ã¥Â…Â¥Ã¤Â½ÂœÃ¤Â¸ÂºÃ©Â»Â˜Ã¨Â®Â¤api keyÃ¯Â¼ÂŒ
+Ã¨Â¿Â™Ã¦Â Â·Ã¥Â®Â¢Ã¦ÂˆÂ·Ã§Â«Â¯Ã¥ÂœÂ¨Ã¨Â¯Â·Ã¦Â±Â‚Ã§Â›Â¸Ã¥Â…Â³Ã¨Â·Â¯Ã§Â”Â±Ã¦Â—Â¶Ã¥ÂÂ¯Ã¤Â»Â¥Ã¦Â—Â Ã©ÂœÂ€Ã¥ÂœÂ¨HeaderÃ¤Â¸Â­Ã¤Â¼Â Ã¥Â…Â¥AuthorizationÃ£Â€Â‚
+Ã¥Â¸Â¦Ã©Â»Â˜Ã¨Â®Â¤api keyÃ§ÂšÂ„Ã¥ÂÂ¯Ã¥ÂŠÂ¨Ã¦Â–Â¹Ã¥Â¼ÂÃ¯Â¼Âš ```bash OPENAI_API_KEY="sk-xxx"
+openai_forward run --port=9999 --workers=1 ``` Ã¦Â³Â¨: Ã¥Â¦Â‚Ã¦ÂÂœÃ¦Â—Â¢Ã¥Â­Â˜Ã¥ÂœÂ¨Ã©Â»Â˜Ã¨Â®Â¤api
+keyÃ¥ÂÂˆÃ¥ÂœÂ¨Ã¨Â¯Â·Ã¦Â±Â‚Ã¥Â¤Â´Ã¤Â¸Â­Ã¤Â¼Â Ã¥Â…Â¥Ã¤ÂºÂ†api keyÃ¯Â¼ÂŒÃ¥ÂˆÂ™Ã¤Â»Â¥Ã¨Â¯Â·Ã¦Â±Â‚Ã¥Â¤Â´Ã¤Â¸Â­Ã§ÂšÂ„api
+keyÃ¤Â¼ÂšÃ¨Â¦Â†Ã§Â›Â–Ã©Â»Â˜Ã¨Â®Â¤api key. ## Docker (Ã¦ÂÂ¨Ã¨ÂÂ) ```bash docker run --
+name="openai-forward" -d -p 9999:8000 beidongjiedeguang/openai-forward:latest
+``` Ã¥Â°Â†Ã¦Â˜Â Ã¥Â°Â„Ã¥Â®Â¿Ã¤Â¸Â»Ã¦ÂœÂºÃ§ÂšÂ„9999Ã§Â«Â¯Ã¥ÂÂ£Ã¯Â¼ÂŒÃ©Â€ÂšÃ¨Â¿Â‡`http://{ip}:9999`Ã¨Â®Â¿Ã©Â—Â®Ã¦ÂœÂÃ¥ÂŠÂ¡Ã£Â€Â‚
+Ã¦Â³Â¨Ã¯Â¼ÂšÃ¥ÂÂŒÃ¦Â Â·Ã¥ÂÂ¯Ã¤Â»Â¥Ã¥ÂœÂ¨Ã¥ÂÂ¯Ã¥ÂŠÂ¨Ã¥Â‘Â½Ã¤Â»Â¤Ã¤Â¸Â­Ã©Â€ÂšÃ¨Â¿Â‡-
+eÃ¤Â¼Â Ã¥Â…Â¥Ã§ÂÂ¯Ã¥Â¢ÂƒÃ¥ÂÂ˜Ã©Â‡ÂOPENAI_API_KEY=sk-xxxÃ¤Â½ÂœÃ¤Â¸ÂºÃ©Â»Â˜Ã¨Â®Â¤api key ## Ã¦ÂºÂÃ§Â ÂÃ©ÂƒÂ¨Ã§Â½Â²
+```bash git clone https://github.com/beidongjiedeguang/openai-forward.git --
+depth=1 cd openai-forward ``` **Ã¤Â½Â¿Ã§Â”Â¨ docker** ```bash docker-compose up ```
+**Ã¦ÂˆÂ–Ã¤Â½Â¿Ã§Â”Â¨pip** ```bash pip install -e . openai-forward run ``` # Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¨Â°ÂƒÃ§Â”Â¨
+Ã¦Â›Â¿Ã¦ÂÂ¢openaiÃ§ÂšÂ„apiÃ¥ÂœÂ°Ã¥ÂÂ€Ã¤Â¸ÂºÃ¨Â¯Â¥Ã¦ÂœÂÃ¥ÂŠÂ¡Ã§ÂšÂ„Ã¥ÂœÂ°Ã¥ÂÂ€Ã¥ÂÂ³Ã¥ÂÂ¯Ã¯Â¼ÂŒÃ¥Â¦Â‚Ã¯Â¼Âš ```bash https://
+api.openai.com/v1/chat/completions ``` Ã¦Â›Â¿Ã¦ÂÂ¢Ã¤Â¸Âº ```bash http://{ip}:{port}/v1/
+chat/completions ``` # Ã©Â…ÂÃ§Â½Â®Ã©Â€Â‰Ã©Â¡Â¹ **`openai-forward run`Ã¥ÂÂ‚Ã¦Â•Â°Ã©Â…ÂÃ§Â½Â®Ã©Â¡Â¹** |
+Ã©Â…ÂÃ§Â½Â®Ã©Â¡Â¹ | Ã¨Â¯Â´Ã¦Â˜Â | Ã©Â»Â˜Ã¨Â®Â¤Ã¥Â€Â¼ | |-----------| --- | :---: | | --port |
+Ã¦ÂœÂÃ¥ÂŠÂ¡Ã§Â«Â¯Ã¥ÂÂ£Ã¥ÂÂ· | 8000 | | --workers | Ã¥Â·Â¥Ã¤Â½ÂœÃ¨Â¿Â›Ã§Â¨Â‹Ã¦Â•Â° | 1 |
+**Ã§ÂÂ¯Ã¥Â¢ÂƒÃ¥ÂÂ˜Ã©Â‡ÂÃ©Â…ÂÃ§Â½Â®Ã©Â¡Â¹** Ã¥ÂÂ‚Ã¨Â€ÂƒÃ©Â¡Â¹Ã§Â›Â®Ã¦Â Â¹Ã§Â›Â®Ã¥Â½Â•Ã¤Â¸Â‹`.env`Ã¦Â–Â‡Ã¤Â»Â¶ | Ã§ÂÂ¯Ã¥Â¢ÂƒÃ¥ÂÂ˜Ã©Â‡Â |
+Ã¨Â¯Â´Ã¦Â˜Â | Ã©Â»Â˜Ã¨Â®Â¤Ã¥Â€Â¼ | |-----------------|---------------------------------------
+--------------------------|:------------------------:| | OPENAI_API_KEY |
+Ã©Â»Â˜Ã¨Â®Â¤openai api keyÃ¯Â¼ÂŒÃ¦Â”Â¯Ã¦ÂŒÂÃ¥Â¤ÂšÃ¤Â¸ÂªÃ©Â»Â˜Ã¨Â®Â¤api key, Ã¤Â»Â¥ `sk-` Ã¥Â¼Â€Ã¥Â¤Â´Ã¯Â¼ÂŒ
+Ã¤Â»Â¥Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â‰Â² | Ã¦Â—Â  | | FORWARD_KEY | Ã¥Â…ÂÃ¨Â®Â¸Ã¨Â°ÂƒÃ§Â”Â¨Ã¦Â–Â¹Ã¤Â½Â¿Ã§Â”Â¨Ã¨Â¯Â¥keyÃ¤Â»Â£Ã¦Â›Â¿openai
+api keyÃ¯Â¼ÂŒÃ¦Â”Â¯Ã¦ÂŒÂÃ¥Â¤ÂšÃ¤Â¸Âªforward key, Ã¤Â»Â¥`fk-` Ã¥Â¼Â€Ã¥Â¤Â´, Ã¤Â»Â¥Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â‰Â² | Ã¦Â—Â  | |
+OPENAI_BASE_URL | Ã¨Â½Â¬Ã¥ÂÂ‘base url | `https://api.openai.com` | | LOG_CHAT |
+Ã¦Â˜Â¯Ã¥ÂÂ¦Ã¨Â®Â°Ã¥Â½Â•Ã¨ÂÂŠÃ¥Â¤Â©Ã¥Â†Â…Ã¥Â®Â¹ | `true` | | ROUTE_PREFIX | Ã¨Â·Â¯Ã§Â”Â±Ã¥Â‰ÂÃ§Â¼Â€ | Ã¦Â—Â  | |
+IP_WHITELIST | ipÃ§Â™Â½Ã¥ÂÂÃ¥ÂÂ•, Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â¼Â€ | Ã¦Â—Â  | | IP_BLACKLIST | ipÃ©Â»Â‘Ã¥ÂÂÃ¥ÂÂ•,
+Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â¼Â€ | Ã¦Â—Â  | # Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â— Ã¤Â¿ÂÃ¥Â­Â˜Ã¨Â·Â¯Ã¥Â¾Â„Ã¥ÂœÂ¨Ã¥Â½Â“Ã¥Â‰ÂÃ§Â›Â®Ã¥Â½Â•Ã¤Â¸Â‹Ã§ÂšÂ„`Log/
+`Ã¨Â·Â¯Ã¥Â¾Â„Ã¤Â¸Â­Ã£Â€Â‚ Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â—Ã¤Â»Â¥ `chat_`Ã¥Â¼Â€Ã¥Â¤Â´,
+Ã©Â»Â˜Ã¨Â®Â¤Ã¦Â¯Â5Ã¨Â½Â®Ã¥Â¯Â¹Ã¨Â¯ÂÃ¥Â†Â™Ã¥Â…Â¥Ã¤Â¸Â€Ã¦Â¬Â¡Ã¦Â–Â‡Ã¤Â»Â¶ Ã¨Â®Â°Ã¥Â½Â•Ã¦Â Â¼Ã¥Â¼ÂÃ¤Â¸Âº ```text {'host': xxx,
+'model': xxx, 'message': [{'user': xxx}, {'assistant': xxx}]} {'assistant':
+xxx} {'host': ...} {'assistant': ...} ... ``` # Ã©Â«Â˜Ã§ÂºÂ§Ã©Â…ÂÃ§Â½Â®
+**Ã¨Â®Â¾Ã§Â½Â®api_keyÃ¤Â¸ÂºÃ¨Â‡ÂªÃ¥Â·Â±Ã¨Â®Â¾Ã§Â½Â®Ã§ÂšÂ„forward key** Ã©ÂœÂ€Ã¨Â¦ÂÃ©Â…ÂÃ§Â½Â® OPENAI_API_KEY Ã¥Â’ÂŒ
+FORWARD_KEY, Ã¤Â¾Â‹Ã¥Â¦Â‚ ```bash OPENAI_API_KEY=sk-******* FORWARD_KEY=fk-****** #
+Ã¨Â¿Â™Ã©Â‡ÂŒfk-tokenÃ§Â”Â±Ã¦ÂˆÂ‘Ã¤Â»Â¬Ã¨Â‡ÂªÃ¥Â·Â±Ã¥Â®ÂšÃ¤Â¹Â‰ ``` Ã¨Â¿Â™Ã©Â‡ÂŒÃ¦ÂˆÂ‘Ã¤Â»Â¬Ã©Â…ÂÃ§Â½Â®Ã¤ÂºÂ†FORWARD_KEYÃ¤Â¸Âº`fk-
+******`,
+Ã©Â‚Â£Ã¤Â¹ÂˆÃ¥ÂÂÃ©ÂÂ¢Ã¥Â®Â¢Ã¦ÂˆÂ·Ã§Â«Â¯Ã¥ÂœÂ¨Ã¨Â°ÂƒÃ§Â”Â¨Ã¦Â—Â¶Ã¥ÂÂªÃ©ÂœÂ€Ã¨Â®Â¾Ã§Â½Â®OPENAI_API_KEYÃ¤Â¸ÂºÃ¦ÂˆÂ‘Ã¤Â»Â¬Ã¨Â‡ÂªÃ¥Â®ÂšÃ¤Â¹Â‰Ã§ÂšÂ„`fk-
+******` Ã¥ÂÂ³Ã¥ÂÂ¯Ã£Â€Â‚
+Ã¨Â¿Â™Ã¦Â Â·Ã§ÂšÂ„Ã¥Â¥Â½Ã¥Â¤Â„Ã¦Â˜Â¯Ã¥ÂœÂ¨Ã¤Â½Â¿Ã§Â”Â¨Ã¤Â¸Â€Ã¤ÂºÂ›Ã©ÂœÂ€Ã¨Â¦ÂÃ¨Â¾Â“Ã¥Â…Â¥OPENAI_API_KEYÃ§ÂšÂ„Ã§Â¬Â¬Ã¤Â¸Â‰Ã¦Â–Â¹Ã¥ÂºÂ”Ã§Â”Â¨Ã¦Â—Â¶Ã¯Â¼ÂŒÃ¦ÂˆÂ‘Ã¤Â»Â¬Ã¥ÂÂ¯Ã¤Â»Â¥Ã¤Â½Â¿Ã§Â”Â¨`fk-
+******`Ã¦ÂÂ­Ã©Â…ÂproxyÃ¤Â½Â¿Ã§Â”Â¨Ã¯Â¼ÂˆÃ¥Â¦Â‚Ã¤Â¸Â‹Ã©ÂÂ¢Ã§ÂšÂ„Ã¤Â¾Â‹Ã¥Â­ÂÃ¯Â¼Â‰
+Ã¨Â€ÂŒÃ¦Â—Â Ã©ÂœÂ€Ã¦Â‹Â…Ã¥Â¿ÂƒOPENAI_API_KEYÃ¨Â¢Â«Ã¦Â³Â„Ã©ÂœÂ²Ã£Â€Â‚ **Ã§Â”Â¨Ã¤Â¾Â‹:** ```bash curl https://
+caloi.top/openai/v1/chat/completions \ -H "Content-Type: application/json" \ -
+H "Authorization: Bearer fk-******" \ -d '{ "model": "gpt-3.5-turbo",
+"messages": [{"role": "user", "content": "Hello!"}] }' ``` **Python** ```diff
+import openai + openai.api_base = "https://caloi.top/openai/v1" -
+openai.api_key = "sk-******" + openai.api_key = "fk-******" ``` **Web
+application** ```bash docker run -d \ -p 3000:3000 \ -e OPENAI_API_KEY="fk-
+******" \ -e BASE_URL="caloi.top/openai" \ -e CODE="" \ yidadaa/chatgpt-next-
+web ```
```

