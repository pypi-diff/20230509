# Comparing `tmp/read_rapidpe-0.2.2.tar.gz` & `tmp/read_rapidpe-0.3.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "read_rapidpe-0.2.2.tar", max compression
+gzip compressed data, was "read_rapidpe-0.3.0.tar", max compression
```

## Comparing `read_rapidpe-0.2.2.tar` & `read_rapidpe-0.3.0.tar`

### file list

```diff
@@ -1,10 +1,10 @@
--rw-r--r--   0        0        0     2399 2023-04-17 13:15:50.969962 read_rapidpe-0.2.2/README.md
--rw-r--r--   0        0        0      627 2023-05-08 11:33:00.637751 read_rapidpe-0.2.2/pyproject.toml
--rw-r--r--   0        0        0      353 2023-04-16 13:12:20.078578 read_rapidpe-0.2.2/read_rapidpe/__init__.py
--rw-r--r--   0        0        0     8684 2023-05-08 03:49:41.967860 read_rapidpe-0.2.2/read_rapidpe/grid_point.py
--rw-r--r--   0        0        0     6083 2023-04-16 13:20:01.614285 read_rapidpe-0.2.2/read_rapidpe/p_astro.py
--rw-r--r--   0        0        0     9718 2023-04-07 15:04:09.805939 read_rapidpe-0.2.2/read_rapidpe/parser.py
--rw-r--r--   0        0        0     1474 2023-04-16 14:05:36.413685 read_rapidpe-0.2.2/read_rapidpe/plot.py
--rw-r--r--   0        0        0    20899 2023-05-08 11:31:16.467507 read_rapidpe-0.2.2/read_rapidpe/result.py
--rw-r--r--   0        0        0     2200 2022-11-25 08:05:18.514011 read_rapidpe-0.2.2/read_rapidpe/transform.py
--rw-r--r--   0        0        0     3330 1970-01-01 00:00:00.000000 read_rapidpe-0.2.2/PKG-INFO
+-rw-r--r--   0        0        0     2399 2023-04-17 13:15:50.969962 read_rapidpe-0.3.0/README.md
+-rw-r--r--   0        0        0      627 2023-05-08 23:20:49.476000 read_rapidpe-0.3.0/pyproject.toml
+-rw-r--r--   0        0        0      353 2023-04-16 13:12:20.078578 read_rapidpe-0.3.0/read_rapidpe/__init__.py
+-rw-r--r--   0        0        0     9603 2023-05-08 23:06:41.529634 read_rapidpe-0.3.0/read_rapidpe/grid_point.py
+-rw-r--r--   0        0        0     6083 2023-04-16 13:20:01.614285 read_rapidpe-0.3.0/read_rapidpe/p_astro.py
+-rw-r--r--   0        0        0     9718 2023-04-07 15:04:09.805939 read_rapidpe-0.3.0/read_rapidpe/parser.py
+-rw-r--r--   0        0        0     1474 2023-04-16 14:05:36.413685 read_rapidpe-0.3.0/read_rapidpe/plot.py
+-rw-r--r--   0        0        0    23411 2023-05-08 23:11:43.053515 read_rapidpe-0.3.0/read_rapidpe/result.py
+-rw-r--r--   0        0        0     2200 2022-11-25 08:05:18.514011 read_rapidpe-0.3.0/read_rapidpe/transform.py
+-rw-r--r--   0        0        0     3330 1970-01-01 00:00:00.000000 read_rapidpe-0.3.0/PKG-INFO
```

### Comparing `read_rapidpe-0.2.2/README.md` & `read_rapidpe-0.3.0/README.md`

 * *Files identical despite different names*

### Comparing `read_rapidpe-0.2.2/pyproject.toml` & `read_rapidpe-0.3.0/pyproject.toml`

 * *Files 15% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 [tool.poetry]
 name = "read-rapidpe"
-version = "0.2.2"
+version = "0.3.0"
 description = "Read and analyse results generated by rapidpe-rift-pipe"
 authors = ["Cory Chu <cory@gwlab.page>"]
 readme = "README.md"
 packages = [{include = "read_rapidpe"}]
 homepage = "https://github.com/c0rychu/read-rapidpe"
 repository = "https://git.ligo.org/yu-kuang.chu/read-rapidpe"
```

### Comparing `read_rapidpe-0.2.2/read_rapidpe/grid_point.py` & `read_rapidpe-0.3.0/read_rapidpe/grid_point.py`

 * *Files 4% similar despite different names*

```diff
@@ -19,27 +19,29 @@
 
     ...
 
     """
     def __init__(self, grid_point=None):
         if grid_point is None:
             self.intrinsic_table = {}
-            self.intrinsic_table_raw = {}
             self.extrinsic_table = {}
-            self.extrinsic_table_raw = {}
             self.xml_filename = ""
         else:
             self.xml_filename = grid_point.xml_filename
-            self.intrinsic_table_raw = grid_point.intrinsic_table_raw
-            self.extrinsic_table_raw = grid_point.extrinsic_table_raw
-            self.intrinsic_table = {}
-            self._set_intrinsic_table()
-            self.extrinsic_table = {}
-            self._set_extrinsic_table()
-            self._fix_intrinsic_table_spin()  # a temporary solution
+            if hasattr(grid_point, "intrinsic_table_raw"):
+                self.intrinsic_table_raw = grid_point.intrinsic_table_raw
+                self.extrinsic_table_raw = grid_point.extrinsic_table_raw
+                self.intrinsic_table = {}
+                self._set_intrinsic_table()
+                self.extrinsic_table = {}
+                self._set_extrinsic_table()
+                self._fix_intrinsic_table_spin()  # a temporary solution
+            else:
+                self.intrinsic_table = grid_point.intrinsic_table
+                self.extrinsic_table = grid_point.extrinsic_table
 
     def _set_intrinsic_table(self):
         # Maps are "rapidpe_name": "canonical_name"
         # Ref: https://lscsoft.docs.ligo.org/pesummary/stable_docs/gw/parameters.html  # noqa E501
         intrinsic_parameter_map = {
                                     "mass1": "mass_1",
                                     "mass2": "mass_2",
@@ -94,14 +96,36 @@
             try:
                 self.extrinsic_table[extrinsic_parameter_map[key]] \
                     = self.extrinsic_table_raw[key]
             except KeyError:
                 pass
 
     @classmethod
+    def from_hdf_grid_point_group(cls,
+                                  hdf_gp_group,
+                                  extrinsic_table=True):
+        """
+        Read the i-th grid point from HDF5 group "/grid_points/i"
+        """
+        grid_point = cls()
+        grid_point.xml_filename = hdf_gp_group.attrs["xml_filename"]
+
+        it = hdf_gp_group["intrinsic_table"][:]
+        grid_point.intrinsic_table = {key: it[key] for key in it.dtype.names}
+
+        if extrinsic_table:
+            try:
+                et = hdf_gp_group["extrinsic_table"][:]
+                grid_point.extrinsic_table = \
+                    {key: et[key] for key in et.dtype.names}
+            except KeyError:
+                pass
+        return cls(grid_point)
+
+    @classmethod
     def from_xml(cls,
                  filename: str,
                  use_numpy=True,
                  use_ligolw=True,
                  extrinsic_table=True):
         """
         Extract XML, assign to "raw" attributes
```

### Comparing `read_rapidpe-0.2.2/read_rapidpe/p_astro.py` & `read_rapidpe-0.3.0/read_rapidpe/p_astro.py`

 * *Files identical despite different names*

### Comparing `read_rapidpe-0.2.2/read_rapidpe/parser.py` & `read_rapidpe-0.3.0/read_rapidpe/parser.py`

 * *Files identical despite different names*

### Comparing `read_rapidpe-0.2.2/read_rapidpe/plot.py` & `read_rapidpe-0.3.0/read_rapidpe/plot.py`

 * *Files identical despite different names*

### Comparing `read_rapidpe-0.2.2/read_rapidpe/result.py` & `read_rapidpe-0.3.0/read_rapidpe/result.py`

 * *Files 10% similar despite different names*

```diff
@@ -5,28 +5,37 @@
 
 from functools import cached_property
 from pathlib import Path
 from joblib import Parallel, delayed
 import re
 import numpy as np
 import h5py
-import pandas as pd
+# import pandas as pd
 from .grid_point import RapidPE_grid_point
 from .transform import transform_m1m2_to_mceta, transform_mceta_to_m1m2
 from .transform import jacobian_mceta_by_m1m2
 
 from matplotlib.tri import Triangulation
 from matplotlib.tri import LinearTriInterpolator, CubicTriInterpolator
 from scipy.interpolate import LinearNDInterpolator, NearestNDInterpolator
 from scipy.interpolate import CloughTocher2DInterpolator
 from scipy.stats import multinomial
 
 # import time  # for profiling
 
 
+def dict_of_ndarray_to_recarray(dict_of_ndarray):
+    # return pd.DataFrame(dict_of_ndarray).to_records(index=False)
+    keys = dict_of_ndarray.keys()
+    names = ", ".join(keys)
+    return np.core.records.fromarrays(
+        [dict_of_ndarray[key] for key in keys], names=names
+        )
+
+
 def unique_with_tolerance(array, tolerance):
     tolerance = np.abs(tolerance)
     sorted_array = np.sort(array)
     diff = np.diff(sorted_array)
     mask = np.append(True, np.where(diff < tolerance, False, True))
     return sorted_array[mask]
 
@@ -124,14 +133,54 @@
     def __copy__(self):
         return RapidPE_result(self)
 
     def copy(self):
         return self.__copy__()
 
     @classmethod
+    def from_hdf(cls, hdf_file, extrinsic_table=True):
+        """
+        Get result from a Rapid-PE HDF file
+
+        Example
+        -------
+            result = RapidPE_result.from_hdf("path/to/hdf_file")
+
+        Attributes
+        ----------
+        hdf_file : string
+            The path to Rapid-PE HDF file
+
+        extrinsic_table : bool
+            Whether loading extrinsic_table as well
+
+        """
+        result = cls()
+        with h5py.File(hdf_file, "r") as f:
+            gps = f["grid_points"]
+            N = len(gps)
+            result.grid_points = np.empty(N, dtype=object)
+            for i, gp in enumerate(gps.values()):
+                result.grid_points[i] = \
+                    RapidPE_grid_point.from_hdf_grid_point_group(
+                        hdf_gp_group=gp,
+                        extrinsic_table=extrinsic_table
+                        )
+            it = f["intrinsic_table"]
+            result.intrinsic_table = {key: it[key] for key in it.dtype.names}
+            result._keys = list(it.dtype.names)
+            for attr in result._keys:
+                try:
+                    setattr(result, attr, result.intrinsic_table[attr])
+                except KeyError:
+                    pass
+
+        return cls(result)
+
+    @classmethod
     def from_run_dir(cls,
                      run_dir,
                      use_numpy=True,
                      use_ligolw=True,
                      extrinsic_table=True,
                      parallel_n=1):
         """
@@ -274,41 +323,62 @@
         filename : str
             The name of the hdf file
 
         compression : str, optional (default: None)
             The compression method, e.g., "gzip", "lzf".
         """
 
-        with h5py.File(hdf_filename, 'w') as f:
+        with h5py.File(hdf_filename, 'w', track_order=True) as f:
 
-            # Cobine intrinsic parameters into "grid_points" dataset
-            result_df = pd.DataFrame({key: getattr(self, key) for key in self._keys})  # noqa: E501
-            result_np = result_df.to_records(index=False)
-            f.create_dataset("grid_points", data=result_np)
+            # Check if there is extrinsic_table
+            gp = self.grid_points[0]
+            extrinsic_table = True if len(gp.extrinsic_table) > 0 else False
 
-            # Create "grid_points_raw" group to hold self.grid_points
+            # Create "grid_points" group to hold self.grid_points
             group_grid_points_raw = \
-                f.create_group("grid_points_raw", track_order=True)
+                f.create_group("grid_points", track_order=True)
 
             for i, gp in enumerate(self.grid_points):
                 group_gp = group_grid_points_raw.create_group(str(i))
 
                 # Add intrinsic_table
-                it = pd.DataFrame(gp.intrinsic_table).to_records(index=False)
+                it = dict_of_ndarray_to_recarray(gp.intrinsic_table)
                 group_gp.create_dataset("intrinsic_table", data=it)
 
                 # Add extrinsic_table
-                et = pd.DataFrame(gp.extrinsic_table).to_records(index=False)
-                group_gp.create_dataset("extrinsic_table",
-                                        data=et,
-                                        compression=compression)
+                if extrinsic_table:
+                    et = dict_of_ndarray_to_recarray(gp.extrinsic_table)
+                    group_gp.create_dataset("extrinsic_table",
+                                            data=et,
+                                            compression=compression)
 
                 # Add xml_filename
                 group_gp.attrs["xml_filename"] = gp.xml_filename
 
+            # Combine intrinsic parameters into "intrinsic_table" dataset
+            result_np = dict_of_ndarray_to_recarray(self.intrinsic_table)
+            f.create_dataset("intrinsic_table", data=result_np)
+
+            # Create virtual dataset for "extrinsic_samples"
+            if extrinsic_table:
+                gps = f["grid_points"]
+                ds0 = f["grid_points/0/extrinsic_table"]
+                n_samples = np.array(
+                    [gp["extrinsic_table"].shape[0] for gp in gps.values()])
+                n_samples = np.cumsum(n_samples)
+                n_samples = np.concatenate([[0], n_samples])
+                layout = h5py.VirtualLayout(shape=(n_samples[-1], ),
+                                            dtype=ds0.dtype)
+
+                for i, gp in enumerate(gps.values()):
+                    vsource = h5py.VirtualSource(gp["extrinsic_table"])
+                    layout[n_samples[i]:n_samples[i+1]] = vsource
+
+                f.create_virtual_dataset('extrinsic_samples', layout)
+
     def do_interpolate_marg_log_likelihood_m1m2(
             self,
             method="linear-scipy",
             gaussian_sigma_to_grid_size_ratio=0.5
             ):
         """
         Perfom triangular interpolation of marg_log_likelihood in
```

### Comparing `read_rapidpe-0.2.2/read_rapidpe/transform.py` & `read_rapidpe-0.3.0/read_rapidpe/transform.py`

 * *Files identical despite different names*

### Comparing `read_rapidpe-0.2.2/PKG-INFO` & `read_rapidpe-0.3.0/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: read-rapidpe
-Version: 0.2.2
+Version: 0.3.0
 Summary: Read and analyse results generated by rapidpe-rift-pipe
 Home-page: https://github.com/c0rychu/read-rapidpe
 Author: Cory Chu
 Author-email: cory@gwlab.page
 Requires-Python: >=3.8,<4.0
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
```

