# Comparing `tmp/azureml_ai_monitoring-0.1.0b1-py3-none-any.whl.zip` & `tmp/azureml_ai_monitoring-0.1.0b2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,28 +1,28 @@
-Zip file size: 17093 bytes, number of entries: 26
--rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-25 09:46 azureml/__init__.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-25 09:46 azureml/ai/__init__.py
--rw-rw-rw-  2.0 fat      246 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/__init__.py
--rw-rw-rw-  2.0 fat      777 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/collector.py
--rw-rw-rw-  2.0 fat      884 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/collector_base.py
--rw-rw-rw-  2.0 fat     3621 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/collector_json.py
--rw-rw-rw-  2.0 fat     1756 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/init.py
--rw-rw-rw-  2.0 fat       25 b- defN 23-Apr-25 09:50 azureml/ai/monitoring/common/__init__.py
--rw-rw-rw-  2.0 fat      331 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/config/__init__.py
--rw-rw-rw-  2.0 fat     6590 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/config/config.py
--rw-rw-rw-  2.0 fat      386 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/context/__init__.py
--rw-rw-rw-  2.0 fat     1987 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/context/context.py
--rw-rw-rw-  2.0 fat      289 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/logger/__init__.py
--rw-rw-rw-  2.0 fat     3723 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/logger/logger.py
--rw-rw-rw-  2.0 fat      309 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/payload/__init__.py
--rw-rw-rw-  2.0 fat      875 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/payload/logdata.py
--rw-rw-rw-  2.0 fat     3351 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/payload/payload.py
--rw-rw-rw-  2.0 fat      302 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/queue/__init__.py
--rw-rw-rw-  2.0 fat     2319 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/queue/queue.py
--rw-rw-rw-  2.0 fat      309 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/worker/__init__.py
--rw-rw-rw-  2.0 fat     4448 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/worker/sender.py
--rw-rw-rw-  2.0 fat     3160 b- defN 23-Apr-25 09:46 azureml/ai/monitoring/worker/worker.py
--rw-rw-rw-  2.0 fat     4345 b- defN 23-Apr-25 09:50 azureml_ai_monitoring-0.1.0b1.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Apr-25 09:50 azureml_ai_monitoring-0.1.0b1.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 23-Apr-25 09:50 azureml_ai_monitoring-0.1.0b1.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     2405 b- defN 23-Apr-25 09:50 azureml_ai_monitoring-0.1.0b1.dist-info/RECORD
-26 files, 42904 bytes uncompressed, 13103 bytes compressed:  69.5%
+Zip file size: 17256 bytes, number of entries: 26
+-rw-rw-rw-  2.0 fat      183 b- defN 23-May-09 07:40 azureml/__init__.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-May-09 07:40 azureml/ai/__init__.py
+-rw-rw-rw-  2.0 fat      246 b- defN 23-May-09 07:40 azureml/ai/monitoring/__init__.py
+-rw-rw-rw-  2.0 fat      777 b- defN 23-May-09 07:40 azureml/ai/monitoring/collector.py
+-rw-rw-rw-  2.0 fat      884 b- defN 23-May-09 07:40 azureml/ai/monitoring/collector_base.py
+-rw-rw-rw-  2.0 fat     3831 b- defN 23-May-09 07:40 azureml/ai/monitoring/collector_json.py
+-rw-rw-rw-  2.0 fat     1756 b- defN 23-May-09 07:40 azureml/ai/monitoring/init.py
+-rw-rw-rw-  2.0 fat       25 b- defN 23-May-09 07:44 azureml/ai/monitoring/common/__init__.py
+-rw-rw-rw-  2.0 fat      331 b- defN 23-May-09 07:40 azureml/ai/monitoring/config/__init__.py
+-rw-rw-rw-  2.0 fat     6185 b- defN 23-May-09 07:40 azureml/ai/monitoring/config/config.py
+-rw-rw-rw-  2.0 fat      386 b- defN 23-May-09 07:40 azureml/ai/monitoring/context/__init__.py
+-rw-rw-rw-  2.0 fat     1987 b- defN 23-May-09 07:40 azureml/ai/monitoring/context/context.py
+-rw-rw-rw-  2.0 fat      289 b- defN 23-May-09 07:40 azureml/ai/monitoring/logger/__init__.py
+-rw-rw-rw-  2.0 fat     4004 b- defN 23-May-09 07:40 azureml/ai/monitoring/logger/logger.py
+-rw-rw-rw-  2.0 fat      309 b- defN 23-May-09 07:40 azureml/ai/monitoring/payload/__init__.py
+-rw-rw-rw-  2.0 fat      875 b- defN 23-May-09 07:40 azureml/ai/monitoring/payload/logdata.py
+-rw-rw-rw-  2.0 fat     3351 b- defN 23-May-09 07:40 azureml/ai/monitoring/payload/payload.py
+-rw-rw-rw-  2.0 fat      302 b- defN 23-May-09 07:40 azureml/ai/monitoring/queue/__init__.py
+-rw-rw-rw-  2.0 fat     2319 b- defN 23-May-09 07:40 azureml/ai/monitoring/queue/queue.py
+-rw-rw-rw-  2.0 fat      309 b- defN 23-May-09 07:40 azureml/ai/monitoring/worker/__init__.py
+-rw-rw-rw-  2.0 fat     4614 b- defN 23-May-09 07:40 azureml/ai/monitoring/worker/sender.py
+-rw-rw-rw-  2.0 fat     3160 b- defN 23-May-09 07:40 azureml/ai/monitoring/worker/worker.py
+-rw-rw-rw-  2.0 fat     4547 b- defN 23-May-09 07:44 azureml_ai_monitoring-0.1.0b2.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-May-09 07:44 azureml_ai_monitoring-0.1.0b2.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        8 b- defN 23-May-09 07:44 azureml_ai_monitoring-0.1.0b2.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     2405 b- defN 23-May-09 07:44 azureml_ai_monitoring-0.1.0b2.dist-info/RECORD
+26 files, 43358 bytes uncompressed, 13266 bytes compressed:  69.4%
```

## zipnote {}

```diff
@@ -60,20 +60,20 @@
 
 Filename: azureml/ai/monitoring/worker/sender.py
 Comment: 
 
 Filename: azureml/ai/monitoring/worker/worker.py
 Comment: 
 
-Filename: azureml_ai_monitoring-0.1.0b1.dist-info/METADATA
+Filename: azureml_ai_monitoring-0.1.0b2.dist-info/METADATA
 Comment: 
 
-Filename: azureml_ai_monitoring-0.1.0b1.dist-info/WHEEL
+Filename: azureml_ai_monitoring-0.1.0b2.dist-info/WHEEL
 Comment: 
 
-Filename: azureml_ai_monitoring-0.1.0b1.dist-info/top_level.txt
+Filename: azureml_ai_monitoring-0.1.0b2.dist-info/top_level.txt
 Comment: 
 
-Filename: azureml_ai_monitoring-0.1.0b1.dist-info/RECORD
+Filename: azureml_ai_monitoring-0.1.0b2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## azureml/ai/monitoring/collector_json.py

```diff
@@ -45,14 +45,20 @@
             self.on_error = on_error
         else:
             self.on_error = _raise_if_exception
 
         self._validate_mdc_config()
 
     def _validate_mdc_config(self):
+        if not self.name or len(self.name) <= 0:
+            # unexpected drop
+            msg = "collection name is not provided"
+            self.on_error(Exception(msg))
+            return False, msg
+
         config = self.config
         if config is None:
             # unexpected drop
             msg = "data collector is not initialized"
             self.on_error(Exception(msg))
             return False, msg
```

## azureml/ai/monitoring/common/__init__.py

```diff
@@ -1 +1 @@
-__version__ = "0.1.0b1"
+__version__ = "0.1.0b2"
```

## azureml/ai/monitoring/config/config.py

```diff
@@ -23,39 +23,42 @@
             port=50011,
             debug=False,
             sample_rate_percentage=default_sample_rate_percentage,
             model_version=None,
             queue_capacity=default_queue_capacity,
             worker_disabled=False,
             worker_count=default_worker_count,
-            use_printer=False,
+            local_capture=False,
             compact_format=False,
     ):
         self._debug = debug
         self._enabled = enabled
         self._sample_rate_percentage = sample_rate_percentage
         self._host = host
         self._port = port
         self._model_version = model_version
         # queue - max length
         self._queue_capacity = queue_capacity
         # worker - disabled for test purpose only
         self._worker_disabled = worker_disabled
         self._worker_count = worker_count
         # payload sender
-        self._use_printer = use_printer
+        self._local_capture = local_capture
         self._compact_format = compact_format
         self._collections = {}
 
     def is_debug(self):
         return self._debug
 
     def enabled(self):
         return self._enabled
 
+    def set_enabled(self, enabled):
+        self._enabled = enabled
+
     def compact_format(self):
         return self._compact_format
 
     def sample_rate_percentage(self):
         return self._sample_rate_percentage
 
     def host(self):
@@ -72,16 +75,16 @@
 
     def worker_disabled(self):
         return self._worker_disabled
 
     def worker_count(self):
         return self._worker_count
 
-    def use_printer(self):
-        return self._use_printer
+    def local_capture(self):
+        return self._local_capture
 
     def add_collection(self, col_name, enabled=False, sample_rate_percentage=100):
         self._collections[col_name] = {
             "enabled": enabled,
             "sampleRatePercentage": sample_rate_percentage,
         }
 
@@ -116,50 +119,48 @@
 def loadConfig(model_version=None):
     debug = is_debug()
     path = os.getenv("AZUREML_MDC_CONFIG_PATH")
 
     if path:
         with open(path) as f:
             cfg = json.load(f)
-            # mdc container is starting
-            if cfg.get("enabled", False):
-                # mdc custom logging is enabled.
-                if cfg.get("sources", {}).get("custom", {}).get("enabled", False):
-                    mdc_cfg = MdcConfig(
-                        enabled=True,
-                        host=os.getenv("AZUREML_MDC_HOST", "127.0.0.1"),
-                        port=int(os.getenv("AZUREML_MDC_PORT", "50011")),
-                        debug=debug,
-                        queue_capacity=int(os.getenv("AZUREML_MDC_QUEUE_CAPACITY", str(default_queue_capacity))),
-                        worker_disabled=os.getenv("AZUREML_MDC_WORKER_DISABLED", "false").lower() == "true",
-                        worker_count=int(os.getenv("AZUREML_MDC_WORKER_COUNT", str(default_worker_count))),
-                        compact_format=os.getenv("AZUREML_MDC_FORMAT_COMPACT", "false").lower() == "true",
-                        use_printer=os.getenv("AZUREML_MDC_WORKER_PRINTONLY", "false").lower() == "true",
-                        model_version=model_version,
-                    )
-
-                    collection_cfg = cfg.get("collections", {})
-                    for n, c in collection_cfg.items():
-                        mdc_cfg.add_collection(n, c.get("enabled", False), c.get("sampleRatePercentage", 100))
+            mdc_cfg = MdcConfig(
+                host=os.getenv("AZUREML_MDC_HOST", "127.0.0.1"),
+                port=int(os.getenv("AZUREML_MDC_PORT", "50011")),
+                debug=debug,
+                model_version=model_version,
+                local_capture=cfg.get("runMode", "cloud") == "local"
+            )
+
+            collection_cfg = cfg.get("collections", {})
+            custom_logging_enabled = False
+            for col_name, c in collection_cfg.items():
+                col_name_lower = col_name.lower()
+                if c.get("enabled", False):
+                    mdc_cfg.add_collection(col_name_lower, True, c.get("sampleRatePercentage", 100))
+                    if col_name_lower not in ('request', 'response'):
+                        custom_logging_enabled = True
+
+            mdc_cfg.set_enabled(custom_logging_enabled)
 
-                    return mdc_cfg
+            return mdc_cfg
 
     enabled = os.getenv("AZUREML_MDC_ENABLED", "false")
     if enabled.lower() == "true":
         return MdcConfig(
             enabled=True,
             host=os.getenv("AZUREML_MDC_HOST", "127.0.0.1"),
             port=int(os.getenv("AZUREML_MDC_PORT", "50011")),
             debug=debug,
             sample_rate_percentage=int(os.getenv("AZUREML_MDC_SAMPLE_RATE", str(default_sample_rate_percentage))),
             queue_capacity=int(os.getenv("AZUREML_MDC_QUEUE_CAPACITY", str(default_queue_capacity))),
             worker_disabled=os.getenv("AZUREML_MDC_WORKER_DISABLED", "false").lower() == "true",
             worker_count=int(os.getenv("AZUREML_MDC_WORKER_COUNT", str(default_worker_count))),
             compact_format=os.getenv("AZUREML_MDC_FORMAT_COMPACT", "false").lower() == "true",
-            use_printer=os.getenv("AZUREML_MDC_WORKER_PRINTONLY", "false").lower() == "true",
+            local_capture=os.getenv("AZUREML_MDC_LOCAL_CAPTURE", "false").lower() == "true",
             model_version=model_version,
         )
 
     return MdcConfig(enabled=False, debug=debug)
 
 
 mdc_config = None
```

## azureml/ai/monitoring/logger/logger.py

```diff
@@ -30,14 +30,19 @@
             "handlers": ["console"]
         },
         "mdc.worker": {
             "level": "INFO",
             "propagate": False,
             "handlers": ["console"]
         },
+        "local.capture": {
+            "level": "INFO",
+            "propagate": False,
+            "handlers": ["console"]
+        },
         "mdc.sender": {
             "level": "WARN",
             "propagate": False,
             "handlers": ["console"]
         },
         "mdc.error": {
             "level": "ERROR",
@@ -87,14 +92,19 @@
             "handlers": ["console"]
         },
         "mdc.worker": {
             "level": "DEBUG",
             "propagate": False,
             "handlers": ["console"]
         },
+        "local.capture": {
+            "level": "DEBUG",
+            "propagate": False,
+            "handlers": ["console"]
+        },
         "mdc.sender": {
             "level": "INFO",
             "propagate": False,
             "handlers": ["console"]
         },
         "mdc.error": {
             "level": "ERROR",
```

## azureml/ai/monitoring/worker/sender.py

```diff
@@ -1,21 +1,21 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 import logging
-import json
+import time
 # pylint: disable=import-error
 import requests
 # pylint: enable=import-error
 
 
 def create_sender(config):
-    if config.use_printer():
-        return PayloadPrinter()
+    if config.local_capture():
+        return LocalCapture()
 
     return MdcSender(config.host(), config.port())
 
 
 def _is_success(status_code):
     return 200 <= status_code < 300
 
@@ -104,15 +104,18 @@
         self.logger.debug("request payload(%s): %s", type(payload), payload)
 
         r = requests.post(url, data=payload, headers=headers)
         self.logger.debug("response: %d, %s", r.status_code, r.text)
         return r.status_code, r.text
 
 
-class PayloadPrinter:
+class LocalCapture:
     def __init__(self):
-        self.logger = logging.getLogger("payload.printer")
+        self.logger = logging.getLogger("local.capture")
 
     def send(self, payload):
-        payload_json = json.dumps(payload.__dict__)
-        self.logger.debug("payload json: %s", payload_json)
+        self.logger.info("%s | %s | %s | %s",
+                         time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime(payload.time())),
+                         payload.designation(),
+                         payload.correlation_id(),
+                         payload.content())
         return True, "done"
```

## Comparing `azureml_ai_monitoring-0.1.0b1.dist-info/METADATA` & `azureml_ai_monitoring-0.1.0b2.dist-info/METADATA`

 * *Files 6% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 Metadata-Version: 2.1
 Name: azureml-ai-monitoring
-Version: 0.1.0b1
-Summary: Azure Machine Learning Model Monitoring SDK V2
+Version: 0.1.0b2
+Summary: Microsoft Azure Machine Learning Python SDK v2 for collecting model data during operationalization
 Author: Microsoft Corporation
 Author-email: azuremlsdk@microsoft.com
 License: MIT License
 Keywords: AzureMachineLearning,ModelMonitoring
 Platform: any
 Classifier: Development Status :: 2 - Pre-Alpha
 Classifier: Intended Audience :: Developers
@@ -26,15 +26,15 @@
 Provides-Extra: test
 Requires-Dist: pytest-subtests ; extra == 'test'
 Requires-Dist: pytest-cov ; extra == 'test'
 Requires-Dist: pytest-xdist ; extra == 'test'
 Requires-Dist: numpy ; extra == 'test'
 Requires-Dist: pandas ; extra == 'test'
 
-# Azure Machine Learning Model Monitoring SDK
+# Microsoft Azure Machine Learning Data Collection SDK v2 for model monitoring
 
 The `azureml-ai-monitoring` package provides an SDK to enable Model Data Collector (MDC) for custom logging allows customers to collect data at arbitrary points in their data pre-processing pipeline. Customers can leverage SDK in `score.py` to log data to desired sink before, during, and after any data transformations. 
 
 Start by importing the `azureml-ai-monitoring` package in `score.py`
 
 ```
 import pandas as pd
@@ -115,12 +115,18 @@
 By default, we'll raise the exception when there is unexpected behavior (like custom logging is not enabled, collection is not enabled, not supported data type), if you want a configurable on_error, you can do it with
 
 ```
 collector = Collector(name="inputs", on_error=lambda e: logging.info("ex:{}".format(e)))
 ```
 # Change Log
 
+## [v0.1.0b2](https://pypi.org/project/azureml-ai-monitoring) (2023.5.9)
+
+**New Features**
+
+- Support local capture
+
 ## [v0.1.0b1](https://pypi.org/project/azureml-ai-monitoring) (2023.4.25)
 
 **New Features**
 
 - Support model data collection for pandas Dataframe.
```

## Comparing `azureml_ai_monitoring-0.1.0b1.dist-info/RECORD` & `azureml_ai_monitoring-0.1.0b2.dist-info/RECORD`

 * *Files 7% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 azureml/__init__.py,sha256=JlCCObuOLZyNhIZlsoL51KtFxiY4xKIIzIRDBcdeu6Y,183
 azureml/ai/__init__.py,sha256=JlCCObuOLZyNhIZlsoL51KtFxiY4xKIIzIRDBcdeu6Y,183
 azureml/ai/monitoring/__init__.py,sha256=ee5clSs8W5I8mbCajj7ZU56T2hl3gpp-2q5zWCWUM78,246
 azureml/ai/monitoring/collector.py,sha256=22QP8BbxoXv16ReS-uvaucqYWd8oZDxppoJupCV4lnc,777
 azureml/ai/monitoring/collector_base.py,sha256=UQzt4gHOKM-q4DWasL-jEpNaNFYN-t9bVX3j0zC6sUM,884
-azureml/ai/monitoring/collector_json.py,sha256=fcbK8c_ywF-xWRurPMASFLG82uTHd7yRV-9D1gARvTs,3621
+azureml/ai/monitoring/collector_json.py,sha256=jrN7_kU42w1OweDOuhMAhEXR-CzXb5zDAJr47O7-3Bg,3831
 azureml/ai/monitoring/init.py,sha256=hTOwaepc7GJT8hoexSGBer8gQ7KtVRki7Oh1qNzNlC0,1756
-azureml/ai/monitoring/common/__init__.py,sha256=XKi_04c9Knqko9Q7ugrCt7m6DaqsfgbKRYECRYSxFmM,25
+azureml/ai/monitoring/common/__init__.py,sha256=lgtAPisMLJVc-biJrppAKB_wCTZFxeOaKHuuJeXu124,25
 azureml/ai/monitoring/config/__init__.py,sha256=KJPcVG7c8Ty2xW7VXK_3Evdmc6k6ac3Sa3BwRNZZbjw,331
-azureml/ai/monitoring/config/config.py,sha256=3rlNnqJ_PQpZU6nE4OZHuEvUwdUoZN1VcihIpy40ozc,6590
+azureml/ai/monitoring/config/config.py,sha256=Mm54x-ky-iYen-89ox1dtNOaspKVIMP8anYLnThlLVw,6185
 azureml/ai/monitoring/context/__init__.py,sha256=isexUqn9Sa7gDn1CKXvbv34OCAPkfeu8VCF36F3K6nk,386
 azureml/ai/monitoring/context/context.py,sha256=rOBOU9b78g00rnZP9aRhKmqmJ_wgdT1TfGO336RTr9Y,1987
 azureml/ai/monitoring/logger/__init__.py,sha256=znJrhFn9aww1DSz7xkxIn36m4e65qPq4P8FAcZjfEZA,289
-azureml/ai/monitoring/logger/logger.py,sha256=hJhLLR88u-AuFM3uu78VkO2BS2TrTUAO3EY_VMZotgU,3723
+azureml/ai/monitoring/logger/logger.py,sha256=ztAJUTnXQKhfXnkUR_3rn6KjRabM2wjLFFQKSYgY0BI,4004
 azureml/ai/monitoring/payload/__init__.py,sha256=2OegTuIHHsH_UZWour1vB73eB6B7JL2cwmpIjOd00nU,309
 azureml/ai/monitoring/payload/logdata.py,sha256=Fg1A3JkMNLhvjVGmP0sWjNb-pFj6zZkrrKkMPfWOEsk,875
 azureml/ai/monitoring/payload/payload.py,sha256=-D-ZZBsEPAw-miSHYHo4mpawFKwXBwBkI834L7xawpQ,3351
 azureml/ai/monitoring/queue/__init__.py,sha256=DANmAGWlW_VZXgJYrLhrGnQex0bIjfWC7oPVZ7RxX68,302
 azureml/ai/monitoring/queue/queue.py,sha256=0SHuPCn8JAyUKjfQt-9Vhd0xi0HPV6E5EqFTGng0Ag0,2319
 azureml/ai/monitoring/worker/__init__.py,sha256=9M78j02quajS5g7fPOzXrzd6JN_k_Rg-dUZDnCm35YA,309
-azureml/ai/monitoring/worker/sender.py,sha256=z2gVtOq332cyVSbpDTZMCaxiiuESVWiJU6qmx5S-80Q,4448
+azureml/ai/monitoring/worker/sender.py,sha256=GUpcreM2JUlBcjZAkAVH6KpJOCux5-6RX9pCTrVC16E,4614
 azureml/ai/monitoring/worker/worker.py,sha256=sKBGqYoP5Noniw8WN3hb2NR1CSjNEW1vvrgmknLy9DA,3160
-azureml_ai_monitoring-0.1.0b1.dist-info/METADATA,sha256=JCKLV2Npa2ZbCgHeAY9LJLC3b5tGSzQZcSxvyxEe-K0,4345
-azureml_ai_monitoring-0.1.0b1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-azureml_ai_monitoring-0.1.0b1.dist-info/top_level.txt,sha256=ZOeEa0TAXo6i5wOjwBoqfIGEuxOcKuscGgNSpizqREY,8
-azureml_ai_monitoring-0.1.0b1.dist-info/RECORD,,
+azureml_ai_monitoring-0.1.0b2.dist-info/METADATA,sha256=yyHnWoGNtesqm7U3e0OURDuNj7qIOwVkluLxFJXZrKo,4547
+azureml_ai_monitoring-0.1.0b2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+azureml_ai_monitoring-0.1.0b2.dist-info/top_level.txt,sha256=ZOeEa0TAXo6i5wOjwBoqfIGEuxOcKuscGgNSpizqREY,8
+azureml_ai_monitoring-0.1.0b2.dist-info/RECORD,,
```

